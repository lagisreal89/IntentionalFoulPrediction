{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import subprocess\n",
    "import sys\n",
    "import papermill as pm\n",
    "import json\n",
    "import math\n",
    "from psycopg2.extras import execute_batch\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "def get_db_config():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../api_data/db.ini')\n",
    "    \n",
    "    return {\n",
    "        'database': config['postgresql']['database'],\n",
    "        'user': config['postgresql']['user'],\n",
    "        'password': config['postgresql']['password'],\n",
    "        'host': config['postgresql']['host'],\n",
    "        'port': config['postgresql']['port']\n",
    "    }\n",
    "# connect to database \n",
    "db_config = get_db_config()\n",
    "conn = psycopg2.connect(\n",
    "    database=db_config['database'],\n",
    "    user=db_config['user'],\n",
    "    password=db_config['password'],\n",
    "    host=db_config['host'],\n",
    "    port=db_config['port']\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "print(\"Database connected successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLAlchemy engine for pandas to_sql functionality\n",
    "CONNECTION_STR = (\n",
    "    f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}\"\n",
    "    f\"@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    ")\n",
    "ENGINE = create_engine(CONNECTION_STR)\n",
    "\n",
    "DATAFRAME = None\n",
    "\n",
    "def log_reg_features():\n",
    "    return\n",
    "\n",
    "def win_probability():\n",
    "    log_model =  LogisticRegression()\n",
    "    lambda_parameter = None\n",
    "    fitted = False\n",
    "    \n",
    "\n",
    "def preprocessing():\n",
    "    global DATAFRAME\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "        select home_fouls, away_fouls, home_3pt_percentage, away_3pt_percentage,\n",
    "        home_free_throw_percentage, away_free_throw_percentage, home_team_fouls, away_team_fouls, possessions_lead_or_trail,\n",
    "        home_ft_bonus, away_ft_bonus, time_left from play_by_play_q4\n",
    "        where period = 4\n",
    "    \"\"\"\n",
    "    db = pd.read_sql(query, ENGINE)\n",
    "    array_type_columns = [\"home_3pt_percentage\", \"away_3pt_percentage\", \"home_free_throw_percentage\", \"away_free_throw_percentage\",\"home_fouls\", \"away_fouls\"]\n",
    "    expanded_dfs = []\n",
    "\n",
    "    for col in array_type_columns:\n",
    "\n",
    "        arrays = db[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "        \n",
    "        max_len = arrays.map(len).max()\n",
    "\n",
    "        padded = arrays.apply(lambda x: x + [np.nan] * (max_len - len(x)))\n",
    "\n",
    "        expanded = pd.DataFrame(\n",
    "            padded.tolist(),\n",
    "            columns=[f\"{col}_{i+1}\" for i in range(max_len)]\n",
    "        )\n",
    "        expanded_dfs.append(expanded)\n",
    "    db = pd.concat([db.drop(columns=array_type_columns)] + expanded_dfs, axis=1)\n",
    "    DATAFRAME = db\n",
    "    print(db.head())\n",
    "\n",
    "def pca():\n",
    "    X = DATAFRAME\n",
    "    X = X.dropna()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=.90)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    print(\"Original shape:\", X.shape)\n",
    "    print(\"Reduced shape:\", X_pca.shape)\n",
    "    print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "    \n",
    "\n",
    "preprocessing()\n",
    "pca()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
