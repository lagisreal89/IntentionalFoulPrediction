{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ebff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import subprocess\n",
    "import sys\n",
    "import papermill as pm\n",
    "import json\n",
    "import math\n",
    "from psycopg2.extras import execute_batch\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import loguniform, randint\n",
    "def get_db_config():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../api_data/db.ini')\n",
    "    \n",
    "    return {\n",
    "        'database': config['postgresql']['database'],\n",
    "        'user': config['postgresql']['user'],\n",
    "        'password': config['postgresql']['password'],\n",
    "        'host': config['postgresql']['host'],\n",
    "        'port': config['postgresql']['port']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected successfully\n",
      "\n",
      "Dataset Split (80/10/10):\n",
      "Training samples: 957640 (80.0%)\n",
      "Validation samples: 119706 (10.0%)\n",
      "Test samples: 119706 (10.0%)\n",
      "Finding optimal lambda\n",
      "Testing 999 lambda values...\n",
      "\n",
      "Optimal lambda found: 0.010 (validation loss: 0.2911)\n",
      "Training model\n",
      "\n",
      "Model Coefficients (λ = 0.010):\n",
      "β₀ (intercept): 0.4385\n",
      "β₁ (S × t̂^λ): 0.2846\n",
      "β₂ (e^(-t̂)): -0.4481\n",
      "β₃ (L): -0.0613\n",
      "Model evaluation\n",
      "\n",
      "Model Evaluation on Test Set\n",
      "Test Accuracy: 0.8730\n",
      "Test Log Loss: 0.2889\n",
      "Test Samples: 119706\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Loss       0.86      0.85      0.85     52499\n",
      "         Win       0.88      0.89      0.89     67207\n",
      "\n",
      "    accuracy                           0.87    119706\n",
      "   macro avg       0.87      0.87      0.87    119706\n",
      "weighted avg       0.87      0.87      0.87    119706\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted\n",
      "Loss Win\n",
      "Actual Loss 44529 7970\n",
      "Win 7235 59972\n",
      "Hyperparameter tuning\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_iter' parameter of RandomizedSearchCV must be an int in the range [1, inf). Got <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001CDD3A42AD0> instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 274\u001b[39m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEval after hyperparameter tuning\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m     nba_model.eval()\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 269\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    267\u001b[39m nba_model.eval()\n\u001b[32m    268\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mHyperparameter tuning\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[43mnba_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEval after hyperparameter tuning\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m nba_model.eval()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 205\u001b[39m, in \u001b[36mnba_win_probability_model.tuning\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m param_distrib = [\n\u001b[32m    191\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]},\n\u001b[32m    192\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnewton-cholesky\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]},\n\u001b[32m    193\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33melasticnet\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m), \u001b[33m'\u001b[39m\u001b[33ml1_ratio\u001b[39m\u001b[33m'\u001b[39m: np.linspace(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]},\n\u001b[32m    194\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnewton-cholesky\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m)},\n\u001b[32m    195\u001b[39m ]\n\u001b[32m    196\u001b[39m rnd_search = RandomizedSearchCV(\n\u001b[32m    197\u001b[39m     estimator=LogisticRegression(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m    198\u001b[39m     param_distributions=param_distrib,\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     scoring=\u001b[33m'\u001b[39m\u001b[33mneg_log_loss\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    204\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mrnd_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m best_params = rnd_search.best_params_\n\u001b[32m    207\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\base.py:1358\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1353\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1354\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1355\u001b[39m )\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\base.py:471\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    464\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    465\u001b[39m \n\u001b[32m    466\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'n_iter' parameter of RandomizedSearchCV must be an int in the range [1, inf). Got <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000001CDD3A42AD0> instead."
     ]
    }
   ],
   "source": [
    "class nba_win_probability_model:\n",
    "    def __init__(self, cursor):\n",
    "        self.model = LogisticRegression(random_state=42)\n",
    "        self.fitted = False\n",
    "        self.lambda_parameter = 1.0\n",
    "        self.time_remaining = None\n",
    "        self.spread_lines = None\n",
    "        self.score_margins = None\n",
    "        self.outcomes = None\n",
    "        self.game_ids = None\n",
    "        self.cursor = cursor\n",
    "        self.X_train,self.X_test,self.X_val = None, None, None\n",
    "        self.y_train,self.y_test,self.y_val = None, None, None\n",
    "    def fetching_outcomes(self):\n",
    "        self.outcomes = {}\n",
    "        query_final_margins = \"\"\"\n",
    "            select game_id, scoremargin\n",
    "            from (\n",
    "                select game_id, scoremargin,\n",
    "                       row_number() over (partition by game_id order by eventnum desc) as rn\n",
    "                from play_by_play_q4\n",
    "                where scoremargin is not null\n",
    "            ) ranked\n",
    "            where rn = 1\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query_final_margins)\n",
    "        final_scores_db = self.cursor.fetchall()\n",
    "        for game_id, score_margin in final_scores_db:\n",
    "            outcome = 0\n",
    "            if 'TIE' not in score_margin and int(score_margin) > 0:\n",
    "                outcome = 1\n",
    "            self.outcomes[game_id] = outcome\n",
    "    \n",
    "    def features(self):\n",
    "        query = \"\"\"\n",
    "            select game_id, eventnum, time_left, scoremargin, moneyline from play_by_play_q4\n",
    "            where scoremargin is not null and period = 4 and moneyline is not null\n",
    "            order by game_id, eventnum\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query)\n",
    "        queried_features = self.cursor.fetchall()\n",
    "        game_id_list, time_list, score_difference_list, spread_list = [], [], [], []\n",
    "        for feature in queried_features:\n",
    "            game_id, eventnum, time_left, margin, spread = feature\n",
    "            if 'TIE' in margin:\n",
    "                margin = 0.0\n",
    "            normalized_time = time_left / 2880.0\n",
    "            normalized_time = max(0.0, min(1.0, normalized_time))\n",
    "            game_id_list.append(game_id)\n",
    "            score_difference_list.append(float(margin))\n",
    "            time_list.append(normalized_time)\n",
    "            spread_list.append(spread)\n",
    "\n",
    "        self.time_remaining = np.array(time_list)\n",
    "        self.spread_lines = np.array(spread_list)\n",
    "        self.score_margins = np.array(score_difference_list)\n",
    "        self.game_ids = np.array(game_id_list)\n",
    "\n",
    "    def feature_matrix(self, score_margins, time_remaining, lambda_parameter, spread_lines):\n",
    "        feature_one = score_margins * (time_remaining ** lambda_parameter)\n",
    "        feature_two = np.exp(-time_remaining)\n",
    "        feature_three = spread_lines\n",
    "        return np.column_stack([feature_one,feature_two,feature_three])\n",
    "\n",
    "    def preprocessing(self):\n",
    "        self.fetching_outcomes()\n",
    "        self.features()\n",
    "        outcome_list = []\n",
    "        for game_id in self.game_ids:\n",
    "            if game_id in self.outcomes:\n",
    "                outcome_list.append(self.outcomes[game_id])\n",
    "        self.training_outcomes = np.array(outcome_list)\n",
    "        return self.training_outcomes\n",
    "    \n",
    "    def model_fit(self):\n",
    "        self.X_train = self.feature_matrix(self.score_margins_train, self.time_remaining_train, self.lambda_parameter, self.spread_lines_train)\n",
    "        self.X_test = self.feature_matrix(self.score_margins_test, self.time_remaining_test, self.lambda_parameter, self.spread_lines_test)\n",
    "        \n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        self.fitted = True\n",
    "\n",
    "        print(f\"\\nModel Coefficients (λ = {self.lambda_parameter:.3f}):\")\n",
    "        print(f\"β₀ (intercept): {self.model.intercept_[0]:.4f}\")\n",
    "        print(f\"β₁ (S × t̂^λ): {self.model.coef_[0][0]:.4f}\")\n",
    "        print(f\"β₂ (e^(-t̂)): {self.model.coef_[0][1]:.4f}\")\n",
    "        print(f\"β₃ (L): {self.model.coef_[0][2]:.4f}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def create_splits(self, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "        outcomes = self.preprocessing()\n",
    "        \n",
    "        indices = np.arange(len(outcomes))\n",
    "        \n",
    "        idx_temp, self.test_indices, y_temp, self.y_test = train_test_split(\n",
    "            indices, \n",
    "            outcomes, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=outcomes\n",
    "        )\n",
    "        \n",
    "        val_ratio = val_size / (train_size + val_size)\n",
    "        \n",
    "        self.train_indices, self.val_indices, self.y_train, self.y_val = train_test_split(\n",
    "            idx_temp, \n",
    "            y_temp, \n",
    "            test_size=val_ratio, \n",
    "            random_state=random_state,\n",
    "            stratify=y_temp\n",
    "        )\n",
    "        \n",
    "        self.score_margins_train = self.score_margins[self.train_indices]\n",
    "        self.time_remaining_train = self.time_remaining[self.train_indices]\n",
    "        self.spread_lines_train = self.spread_lines[self.train_indices]\n",
    "        \n",
    "        self.score_margins_val = self.score_margins[self.val_indices]\n",
    "        self.time_remaining_val = self.time_remaining[self.val_indices]\n",
    "        self.spread_lines_val = self.spread_lines[self.val_indices]\n",
    "        \n",
    "        self.score_margins_test = self.score_margins[self.test_indices]\n",
    "        self.time_remaining_test = self.time_remaining[self.test_indices]\n",
    "        self.spread_lines_test = self.spread_lines[self.test_indices]\n",
    "        \n",
    "        print(f\"\\nDataset Split (80/10/10):\")\n",
    "        print(f\"Training samples: {len(self.train_indices)} ({len(self.train_indices)/len(outcomes)*100:.1f}%)\")\n",
    "        print(f\"Validation samples: {len(self.val_indices)} ({len(self.val_indices)/len(outcomes)*100:.1f}%)\")\n",
    "        print(f\"Test samples: {len(self.test_indices)} ({len(self.test_indices)/len(outcomes)*100:.1f}%)\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def win_probability(self, score_differential, time_remaining, spread):\n",
    "        score_differential = np.atleast_1d(score_differential)\n",
    "        time_remaining = np.atleast_1d(time_remaining)\n",
    "        spread = np.atleast_1d(spread)\n",
    "        feature_one = score_differential * (time_remaining ** self.lambda_parameter)\n",
    "        feature_two = np.exp(-time_remaining)\n",
    "        feature_three = spread\n",
    "        X = np.column_stack([feature_one,feature_two,feature_three])\n",
    "        probability = self.model.predict_proba(X)[:,1]\n",
    "        return probability\n",
    "    \n",
    "    def eval(self):\n",
    "        test_probability = self.model.predict_proba(self.X_test)[:,1]\n",
    "        test_prediction = (test_probability > .5).astype(int)\n",
    "        accuracy = accuracy_score(self.y_test, test_prediction)\n",
    "        logloss = log_loss(self.y_test, test_probability)\n",
    "\n",
    "        print(f\"\\nModel Evaluation on Test Set\")\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Test Log Loss: {logloss:.4f}\")\n",
    "        print(f\"Test Samples: {len(self.y_test)}\")\n",
    "        \n",
    "        print(f\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, test_prediction, target_names=['Loss', 'Win']))\n",
    "        \n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(self.y_test, test_prediction)\n",
    "        print(f\"Predicted\")\n",
    "        print(f\"Loss Win\")\n",
    "        print(f\"Actual Loss {cm[0,0]:4d} {cm[0,1]:4d}\")\n",
    "        print(f\"Win {cm[1,0]:4d} {cm[1,1]:4d}\")\n",
    "\n",
    "    def optimal_lambda(self, lambda_range=np.arange(0.01, 10, .01)):\n",
    "        best_lambda = None \n",
    "        lowest_loss = float('inf')\n",
    "        \n",
    "        print(f\"Testing {len(lambda_range)} lambda values...\")\n",
    "        \n",
    "        for lambda_val in lambda_range:\n",
    "            X_train_lambda = self.feature_matrix(self.score_margins_train, self.time_remaining_train, lambda_val, self.spread_lines_train)\n",
    "            X_val_lambda = self.feature_matrix(self.score_margins_val, self.time_remaining_val, lambda_val, self.spread_lines_val)\n",
    "            \n",
    "            temp_model = LogisticRegression(random_state=42)\n",
    "            temp_model.fit(X_train_lambda, self.y_train)\n",
    "            \n",
    "            val_probs = temp_model.predict_proba(X_val_lambda)[:, 1]\n",
    "            val_loss = log_loss(self.y_val, val_probs)\n",
    "            \n",
    "            if val_loss < lowest_loss:\n",
    "                lowest_loss = val_loss\n",
    "                best_lambda = lambda_val\n",
    "        \n",
    "        self.lambda_parameter = best_lambda\n",
    "        print(f\"\\nOptimal lambda found: {best_lambda:.3f} (validation loss: {lowest_loss:.4f})\")\n",
    "        return best_lambda\n",
    "        \n",
    "    def tuning(self):\n",
    "        \n",
    "        param_distrib = [\n",
    "            {'penalty': ['l1'], 'solver': ['liblinear', 'saga'], 'C': loguniform(1e-4, 1e4), 'class_weight': [None, 'balanced']},\n",
    "            {'penalty': ['l2'], 'solver': ['newton-cg', 'newton-cholesky', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': loguniform(1e-4, 1e4), 'class_weight': [None, 'balanced']},\n",
    "            {'penalty': ['elasticnet'], 'solver': ['saga'], 'C': loguniform(1e-4, 1e4), 'l1_ratio': np.linspace(0, 1, 10), 'class_weight': [None, 'balanced']},\n",
    "            {'penalty': [None], 'solver': ['newton-cg', 'newton-cholesky', 'lbfgs', 'sag', 'saga'], 'C': loguniform(1e-4, 1e4)},\n",
    "        ]\n",
    "        rnd_search = RandomizedSearchCV(\n",
    "            estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "            param_distributions=param_distrib,\n",
    "            n_iter=150,\n",
    "            cv=5,\n",
    "            random_state=42,\n",
    "            n_jobs=1,\n",
    "            scoring='neg_log_loss'\n",
    "        )\n",
    "        rnd_search.fit(self.X_train,self.y_train)\n",
    "        best_params = rnd_search.best_params_\n",
    "        print(f\"Parameters: {best_params}\")\n",
    "        final_model = rnd_search.best_estimator_\n",
    "        print(f\"final model: {final_model}\")\n",
    "        self.model = LogisticRegression(random_state=42, **rnd_search.best_params_)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        return best_params\n",
    "\n",
    "def money_line_to_db(conn, cursor):\n",
    "    moneyline_df = pd.read_csv(\"../api_data/rotowire_nba_games_archive.csv\")\n",
    "    for _,row in moneyline_df.iterrows():\n",
    "        updates = []\n",
    "        moneyline_df_home_abbrev = row['home_team_abbrev']\n",
    "        moneyline_df_away_abbrev = row['visit_team_abbrev']\n",
    "        moneyline_df_date = row['game_date'].split(\" \")[0]\n",
    "        moneyline = row['line']\n",
    "        query = \"\"\"\n",
    "            select game_id, eventnum from play_by_play_q4\n",
    "            where home_team_abbrev = %s and away_team_abbrev = %s and game_date = %s and moneyline is null\n",
    "            group by game_id, eventnum\n",
    "        \"\"\"\n",
    "        cursor.execute(query, (moneyline_df_home_abbrev,moneyline_df_away_abbrev,moneyline_df_date))\n",
    "        db_data = cursor.fetchall()\n",
    "        for game_id, eventnum in db_data:\n",
    "            updates.append((moneyline, game_id, eventnum))\n",
    "        update_query = \"\"\"\n",
    "                update play_by_play_q4\n",
    "                set moneyline = %s \n",
    "                where game_id = %s and eventnum = %s\n",
    "        \"\"\"\n",
    "        execute_batch(cursor, update_query, updates, page_size=1000)\n",
    "        conn.commit()\n",
    "        print(f\"Updated {len(updates)} rows successfully\")\n",
    "    cursor.close()\n",
    "    conn.close()    \n",
    "    \n",
    "def main():\n",
    "    # connect to database \n",
    "    db_config = get_db_config()\n",
    "    conn = psycopg2.connect(\n",
    "        database=db_config['database'],\n",
    "        user=db_config['user'],\n",
    "        password=db_config['password'],\n",
    "        host=db_config['host'],\n",
    "        port=db_config['port']\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    # Create SQLAlchemy engine for pandas to_sql functionality\n",
    "    CONNECTION_STR = (\n",
    "        f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}\"\n",
    "        f\"@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "    )\n",
    "    ENGINE = create_engine(CONNECTION_STR)\n",
    "    print(\"Database connected successfully\")\n",
    "    nba_model = nba_win_probability_model(cursor)\n",
    "    nba_model.create_splits()\n",
    "    print(\"Finding optimal lambda\")\n",
    "    optimal_lambda = nba_model.optimal_lambda()\n",
    "    print(\"Training model\")\n",
    "    nba_model.model_fit()\n",
    "    print(\"Model evaluation\")\n",
    "    nba_model.eval()\n",
    "    print('Hyperparameter tuning')\n",
    "    nba_model.tuning()\n",
    "    print(\"Eval after hyperparameter tuning\")\n",
    "    nba_model.eval()\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
