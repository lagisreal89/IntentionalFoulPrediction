{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ebff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import subprocess\n",
    "import sys\n",
    "import papermill as pm\n",
    "import json\n",
    "import math\n",
    "from psycopg2.extras import execute_batch\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report, confusion_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import loguniform, randint\n",
    "def get_db_config():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../api_data/db.ini')\n",
    "    \n",
    "    return {\n",
    "        'database': config['postgresql']['database'],\n",
    "        'user': config['postgresql']['user'],\n",
    "        'password': config['postgresql']['password'],\n",
    "        'host': config['postgresql']['host'],\n",
    "        'port': config['postgresql']['port']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b97189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected successfully\n",
      "\n",
      "Dataset Split (80/10/10):\n",
      "Training samples: 957640 (80.0%)\n",
      "Validation samples: 119706 (10.0%)\n",
      "Test samples: 119706 (10.0%)\n",
      "Finding optimal lambda\n",
      "Testing 999 lambda values...\n",
      "\n",
      "Optimal lambda found: 0.010 (validation loss: 0.2911)\n",
      "Training model\n",
      "\n",
      "Model Coefficients (λ = 0.010):\n",
      "β₀ (intercept): 0.4385\n",
      "β₁ (S × t̂^λ): 0.2846\n",
      "β₂ (e^(-t̂)): -0.4481\n",
      "β₃ (L): -0.0613\n",
      "Model evaluation\n",
      "\n",
      "Model Evaluation on Test Set\n",
      "Test Accuracy: 0.8730\n",
      "Test Log Loss: 0.2889\n",
      "Test Samples: 119706\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Loss       0.86      0.85      0.85     52499\n",
      "         Win       0.88      0.89      0.89     67207\n",
      "\n",
      "    accuracy                           0.87    119706\n",
      "   macro avg       0.87      0.87      0.87    119706\n",
      "weighted avg       0.87      0.87      0.87    119706\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted\n",
      "Loss Win\n",
      "Actual Loss 44529 7970\n",
      "Win 7235 59972\n",
      "Hyperparameter tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 274\u001b[39m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEval after hyperparameter tuning\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m     nba_model.eval()\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 269\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    267\u001b[39m nba_model.eval()\n\u001b[32m    268\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mHyperparameter tuning\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[43mnba_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEval after hyperparameter tuning\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m nba_model.eval()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 205\u001b[39m, in \u001b[36mnba_win_probability_model.tuning\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m param_distrib = [\n\u001b[32m    191\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml1\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]},\n\u001b[32m    192\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnewton-cholesky\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]},\n\u001b[32m    193\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33melasticnet\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m), \u001b[33m'\u001b[39m\u001b[33ml1_ratio\u001b[39m\u001b[33m'\u001b[39m: np.linspace(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mclass_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]},\n\u001b[32m    194\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[33m'\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnewton-cholesky\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m: loguniform(\u001b[32m1e-4\u001b[39m, \u001b[32m1e4\u001b[39m)},\n\u001b[32m    195\u001b[39m ]\n\u001b[32m    196\u001b[39m rnd_search = RandomizedSearchCV(\n\u001b[32m    197\u001b[39m     estimator=LogisticRegression(random_state=\u001b[32m42\u001b[39m, max_iter=\u001b[32m1000\u001b[39m),\n\u001b[32m    198\u001b[39m     param_distributions=param_distrib,\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     scoring=\u001b[33m'\u001b[39m\u001b[33mneg_log_loss\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    204\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mrnd_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m best_params = rnd_search.best_params_\n\u001b[32m    207\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:560\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    557\u001b[39m         alpha = (\u001b[32m1.0\u001b[39m / C) * (\u001b[32m1\u001b[39m - l1_ratio)\n\u001b[32m    558\u001b[39m         beta = (\u001b[32m1.0\u001b[39m / C) * l1_ratio\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     w0, n_iter_i, warm_start_sag = \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msolver must be one of \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33msag\u001b[39m\u001b[33m'\u001b[39m\u001b[33m}, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m % solver\n\u001b[32m    581\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[39m, in \u001b[36msag_solver\u001b[39m\u001b[34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[39m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[32m    318\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCurrent sag implementation does not handle \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    322\u001b[39m sag = sag64 \u001b[38;5;28;01mif\u001b[39;00m X.dtype == np.float64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m num_seen, n_iter_ = \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ == max_iter:\n\u001b[32m    348\u001b[39m     warnings.warn(\n\u001b[32m    349\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    350\u001b[39m         ConvergenceWarning,\n\u001b[32m    351\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class nba_win_probability_model:\n",
    "    def __init__(self, cursor):\n",
    "        self.model = LogisticRegression(random_state=42)\n",
    "        self.fitted = False\n",
    "        self.lambda_parameter = 1.0\n",
    "        self.time_remaining = None\n",
    "        self.spread_lines = None\n",
    "        self.score_margins = None\n",
    "        self.outcomes = None\n",
    "        self.game_ids = None\n",
    "        self.cursor = cursor\n",
    "        self.X_train,self.X_test,self.X_val = None, None, None\n",
    "        self.y_train,self.y_test,self.y_val = None, None, None\n",
    "    def fetching_outcomes(self):\n",
    "        self.outcomes = {}\n",
    "        query_final_margins = \"\"\"\n",
    "            select game_id, scoremargin\n",
    "            from (\n",
    "                select game_id, scoremargin,\n",
    "                       row_number() over (partition by game_id order by eventnum desc) as rn\n",
    "                from play_by_play_q4\n",
    "                where scoremargin is not null\n",
    "            ) ranked\n",
    "            where rn = 1\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query_final_margins)\n",
    "        final_scores_db = self.cursor.fetchall()\n",
    "        for game_id, score_margin in final_scores_db:\n",
    "            outcome = 0\n",
    "            if 'TIE' not in score_margin and int(score_margin) > 0:\n",
    "                outcome = 1\n",
    "            self.outcomes[game_id] = outcome\n",
    "    \n",
    "    def features(self):\n",
    "        query = \"\"\"\n",
    "            select game_id, eventnum, time_left, scoremargin, moneyline from play_by_play_q4\n",
    "            where scoremargin is not null and period = 4 and moneyline is not null\n",
    "            order by game_id, eventnum\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query)\n",
    "        queried_features = self.cursor.fetchall()\n",
    "        game_id_list, time_list, score_difference_list, spread_list = [], [], [], []\n",
    "        for feature in queried_features:\n",
    "            game_id, eventnum, time_left, margin, spread = feature\n",
    "            if 'TIE' in margin:\n",
    "                margin = 0.0\n",
    "            normalized_time = time_left / 2880.0\n",
    "            normalized_time = max(0.0, min(1.0, normalized_time))\n",
    "            game_id_list.append(game_id)\n",
    "            score_difference_list.append(float(margin))\n",
    "            time_list.append(normalized_time)\n",
    "            spread_list.append(spread)\n",
    "\n",
    "        self.time_remaining = np.array(time_list)\n",
    "        self.spread_lines = np.array(spread_list)\n",
    "        self.score_margins = np.array(score_difference_list)\n",
    "        self.game_ids = np.array(game_id_list)\n",
    "\n",
    "    def feature_matrix(self, score_margins, time_remaining, lambda_parameter, spread_lines):\n",
    "        feature_one = score_margins * (time_remaining ** lambda_parameter)\n",
    "        feature_two = np.exp(-time_remaining)\n",
    "        feature_three = spread_lines\n",
    "        return np.column_stack([feature_one,feature_two,feature_three])\n",
    "\n",
    "    def preprocessing(self):\n",
    "        self.fetching_outcomes()\n",
    "        self.features()\n",
    "        outcome_list = []\n",
    "        for game_id in self.game_ids:\n",
    "            if game_id in self.outcomes:\n",
    "                outcome_list.append(self.outcomes[game_id])\n",
    "        self.training_outcomes = np.array(outcome_list)\n",
    "        return self.training_outcomes\n",
    "    \n",
    "    def model_fit(self):\n",
    "        self.X_train = self.feature_matrix(self.score_margins_train, self.time_remaining_train, self.lambda_parameter, self.spread_lines_train)\n",
    "        self.X_test = self.feature_matrix(self.score_margins_test, self.time_remaining_test, self.lambda_parameter, self.spread_lines_test)\n",
    "        \n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        self.fitted = True\n",
    "\n",
    "        print(f\"\\nModel Coefficients (λ = {self.lambda_parameter:.3f}):\")\n",
    "        print(f\"β₀ (intercept): {self.model.intercept_[0]:.4f}\")\n",
    "        print(f\"β₁ (S × t̂^λ): {self.model.coef_[0][0]:.4f}\")\n",
    "        print(f\"β₂ (e^(-t̂)): {self.model.coef_[0][1]:.4f}\")\n",
    "        print(f\"β₃ (L): {self.model.coef_[0][2]:.4f}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def create_splits(self, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "        outcomes = self.preprocessing()\n",
    "        \n",
    "        indices = np.arange(len(outcomes))\n",
    "        \n",
    "        idx_temp, self.test_indices, y_temp, self.y_test = train_test_split(\n",
    "            indices, \n",
    "            outcomes, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=outcomes\n",
    "        )\n",
    "        \n",
    "        val_ratio = val_size / (train_size + val_size)\n",
    "        \n",
    "        self.train_indices, self.val_indices, self.y_train, self.y_val = train_test_split(\n",
    "            idx_temp, \n",
    "            y_temp, \n",
    "            test_size=val_ratio, \n",
    "            random_state=random_state,\n",
    "            stratify=y_temp\n",
    "        )\n",
    "        \n",
    "        self.score_margins_train = self.score_margins[self.train_indices]\n",
    "        self.time_remaining_train = self.time_remaining[self.train_indices]\n",
    "        self.spread_lines_train = self.spread_lines[self.train_indices]\n",
    "        \n",
    "        self.score_margins_val = self.score_margins[self.val_indices]\n",
    "        self.time_remaining_val = self.time_remaining[self.val_indices]\n",
    "        self.spread_lines_val = self.spread_lines[self.val_indices]\n",
    "        \n",
    "        self.score_margins_test = self.score_margins[self.test_indices]\n",
    "        self.time_remaining_test = self.time_remaining[self.test_indices]\n",
    "        self.spread_lines_test = self.spread_lines[self.test_indices]\n",
    "        \n",
    "        print(f\"\\nDataset Split (80/10/10):\")\n",
    "        print(f\"Training samples: {len(self.train_indices)} ({len(self.train_indices)/len(outcomes)*100:.1f}%)\")\n",
    "        print(f\"Validation samples: {len(self.val_indices)} ({len(self.val_indices)/len(outcomes)*100:.1f}%)\")\n",
    "        print(f\"Test samples: {len(self.test_indices)} ({len(self.test_indices)/len(outcomes)*100:.1f}%)\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def win_probability(self, score_differential, time_remaining, spread):\n",
    "        score_differential = np.atleast_1d(score_differential)\n",
    "        time_remaining = np.atleast_1d(time_remaining)\n",
    "        spread = np.atleast_1d(spread)\n",
    "        feature_one = score_differential * (time_remaining ** self.lambda_parameter)\n",
    "        feature_two = np.exp(-time_remaining)\n",
    "        feature_three = spread\n",
    "        X = np.column_stack([feature_one,feature_two,feature_three])\n",
    "        probability = self.model.predict_proba(X)[:,1]\n",
    "        return probability\n",
    "    \n",
    "    def eval(self):\n",
    "        test_probability = self.model.predict_proba(self.X_test)[:,1]\n",
    "        test_prediction = (test_probability > .5).astype(int)\n",
    "        accuracy = accuracy_score(self.y_test, test_prediction)\n",
    "        logloss = log_loss(self.y_test, test_probability)\n",
    "\n",
    "        print(f\"\\nModel Evaluation on Test Set\")\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Test Log Loss: {logloss:.4f}\")\n",
    "        print(f\"Test Samples: {len(self.y_test)}\")\n",
    "        \n",
    "        print(f\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, test_prediction, target_names=['Loss', 'Win']))\n",
    "        \n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(self.y_test, test_prediction)\n",
    "        print(f\"Predicted\")\n",
    "        print(f\"Loss Win\")\n",
    "        print(f\"Actual Loss {cm[0,0]:4d} {cm[0,1]:4d}\")\n",
    "        print(f\"Win {cm[1,0]:4d} {cm[1,1]:4d}\")\n",
    "\n",
    "    def optimal_lambda(self, lambda_range=np.arange(0.01, 10, .01)):\n",
    "        best_lambda = None \n",
    "        lowest_loss = float('inf')\n",
    "        \n",
    "        print(f\"Testing {len(lambda_range)} lambda values...\")\n",
    "        \n",
    "        for lambda_val in lambda_range:\n",
    "            X_train_lambda = self.feature_matrix(self.score_margins_train, self.time_remaining_train, lambda_val, self.spread_lines_train)\n",
    "            X_val_lambda = self.feature_matrix(self.score_margins_val, self.time_remaining_val, lambda_val, self.spread_lines_val)\n",
    "            \n",
    "            temp_model = LogisticRegression(random_state=42)\n",
    "            temp_model.fit(X_train_lambda, self.y_train)\n",
    "            \n",
    "            val_probs = temp_model.predict_proba(X_val_lambda)[:, 1]\n",
    "            val_loss = log_loss(self.y_val, val_probs)\n",
    "            \n",
    "            if val_loss < lowest_loss:\n",
    "                lowest_loss = val_loss\n",
    "                best_lambda = lambda_val\n",
    "        \n",
    "        self.lambda_parameter = best_lambda\n",
    "        print(f\"\\nOptimal lambda found: {best_lambda:.3f} (validation loss: {lowest_loss:.4f})\")\n",
    "        return best_lambda\n",
    "        \n",
    "    def tuning(self):\n",
    "        \n",
    "        param_distrib = [\n",
    "            {'penalty': ['l1'], 'solver': ['liblinear', 'saga'], 'C': loguniform(1e-4, 1e4), 'class_weight': [None, 'balanced']},\n",
    "            {'penalty': ['l2'], 'solver': ['newton-cg', 'newton-cholesky', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': loguniform(1e-4, 1e4), 'class_weight': [None, 'balanced']},\n",
    "            {'penalty': ['elasticnet'], 'solver': ['saga'], 'C': loguniform(1e-4, 1e4), 'l1_ratio': np.linspace(0, 1, 10), 'class_weight': [None, 'balanced']},\n",
    "            {'penalty': [None], 'solver': ['newton-cg', 'newton-cholesky', 'lbfgs', 'sag', 'saga'], 'C': loguniform(1e-4, 1e4)},\n",
    "        ]\n",
    "        rnd_search = RandomizedSearchCV(\n",
    "            estimator=LogisticRegression(random_state=42, max_iter=1000),\n",
    "            param_distributions=param_distrib,\n",
    "            n_iter=150,\n",
    "            cv=5,\n",
    "            random_state=42,\n",
    "            n_jobs=1,\n",
    "            scoring='neg_log_loss'\n",
    "        )\n",
    "        rnd_search.fit(self.X_train,self.y_train)\n",
    "        best_params = rnd_search.best_params_\n",
    "        print(f\"Parameters: {best_params}\")\n",
    "        final_model = rnd_search.best_estimator_\n",
    "        print(f\"final model: {final_model}\")\n",
    "        self.model = LogisticRegression(random_state=42, **rnd_search.best_params_)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        return best_params\n",
    "\n",
    "def money_line_to_db(conn, cursor):\n",
    "    moneyline_df = pd.read_csv(\"../api_data/rotowire_nba_games_archive.csv\")\n",
    "    for _,row in moneyline_df.iterrows():\n",
    "        updates = []\n",
    "        moneyline_df_home_abbrev = row['home_team_abbrev']\n",
    "        moneyline_df_away_abbrev = row['visit_team_abbrev']\n",
    "        moneyline_df_date = row['game_date'].split(\" \")[0]\n",
    "        moneyline = row['line']\n",
    "        query = \"\"\"\n",
    "            select game_id, eventnum from play_by_play_q4\n",
    "            where home_team_abbrev = %s and away_team_abbrev = %s and game_date = %s and moneyline is null\n",
    "            group by game_id, eventnum\n",
    "        \"\"\"\n",
    "        cursor.execute(query, (moneyline_df_home_abbrev,moneyline_df_away_abbrev,moneyline_df_date))\n",
    "        db_data = cursor.fetchall()\n",
    "        for game_id, eventnum in db_data:\n",
    "            updates.append((moneyline, game_id, eventnum))\n",
    "        update_query = \"\"\"\n",
    "                update play_by_play_q4\n",
    "                set moneyline = %s \n",
    "                where game_id = %s and eventnum = %s\n",
    "        \"\"\"\n",
    "        execute_batch(cursor, update_query, updates, page_size=1000)\n",
    "        conn.commit()\n",
    "        print(f\"Updated {len(updates)} rows successfully\")\n",
    "    cursor.close()\n",
    "    conn.close()    \n",
    "    \n",
    "def main():\n",
    "    # connect to database \n",
    "    db_config = get_db_config()\n",
    "    conn = psycopg2.connect(\n",
    "        database=db_config['database'],\n",
    "        user=db_config['user'],\n",
    "        password=db_config['password'],\n",
    "        host=db_config['host'],\n",
    "        port=db_config['port']\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    # Create SQLAlchemy engine for pandas to_sql functionality\n",
    "    CONNECTION_STR = (\n",
    "        f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}\"\n",
    "        f\"@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "    )\n",
    "    ENGINE = create_engine(CONNECTION_STR)\n",
    "    print(\"Database connected successfully\")\n",
    "    nba_model = nba_win_probability_model(cursor)\n",
    "    nba_model.create_splits()\n",
    "    print(\"Finding optimal lambda\")\n",
    "    optimal_lambda = nba_model.optimal_lambda()\n",
    "    print(\"Training model\")\n",
    "    nba_model.model_fit()\n",
    "    print(\"Model evaluation\")\n",
    "    nba_model.eval()\n",
    "    print('Hyperparameter tuning')\n",
    "    nba_model.tuning()\n",
    "    print(\"Eval after hyperparameter tuning\")\n",
    "    nba_model.eval()\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
