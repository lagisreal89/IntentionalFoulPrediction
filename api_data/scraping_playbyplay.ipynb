{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d724977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from nba_api.stats.endpoints import playbyplayv2, leaguegamefinder, boxscoretraditionalv3, playerdashboardbyyearoveryear, boxscoresummaryv2\n",
    "from sqlalchemy import create_engine, text\n",
    "import subprocess\n",
    "import sys\n",
    "import papermill as pm\n",
    "import json\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from psycopg2.extras import execute_batch\n",
    "def get_db_config():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('db.ini')\n",
    "    \n",
    "    return {\n",
    "        'database': config['postgresql']['database'],\n",
    "        'user': config['postgresql']['user'],\n",
    "        'password': config['postgresql']['password'],\n",
    "        'host': config['postgresql']['host'],\n",
    "        'port': config['postgresql']['port']\n",
    "    }\n",
    "\n",
    "def create_table():\n",
    "    try:      \n",
    "        # Create the play_by_play_q4 table if it doesn't exist\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS play_by_play_q4 (\n",
    "            game_id VARCHAR(20),\n",
    "            eventnum INT,\n",
    "            eventmsgtype INT,\n",
    "            eventmsgactiontype INT,\n",
    "            period INT,\n",
    "            wctimestring VARCHAR(20),\n",
    "            pctimestring VARCHAR(20),\n",
    "            homedescription TEXT,\n",
    "            neutraldescription TEXT,\n",
    "            visitordescription TEXT,\n",
    "            score VARCHAR(20),\n",
    "            scoremargin VARCHAR(10),\n",
    "            ADD COLUMN IF NOT EXISTS home_players INT[],\n",
    "            ADD COLUMN IF NOT EXISTS away_players INT[],\n",
    "            ADD COLUMN IF NOT EXISTS home_3pt_percentage double precision[],\n",
    "            ADD COLUMN IF NOT EXISTS away_3pt_percentage double precision[],\n",
    "            add COLUMN if not exists home_free_throw_percentage double precision[],\n",
    "            add COLUMN if not exists away_free_throw_percentage double precision[],\n",
    "            add column if not exists home_fouls int[],\n",
    "            add column if not exists away_fouls int[],\n",
    "            PRIMARY KEY (game_id, eventnum)\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Table play_by_play_q4 created successfully or already exists\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def alter_table():\n",
    "    try: \n",
    "        alter_table_query = \"\"\"\n",
    "        ALTER TABLE play_by_play_q4\n",
    "        ADD COLUMN IF NOT EXISTS home_players INT[],\n",
    "        ADD COLUMN IF NOT EXISTS away_players INT[],\n",
    "        ADD COLUMN IF NOT EXISTS home_3pt_percentage double precision[],\n",
    "        ADD COLUMN IF NOT EXISTS away_3pt_percentage double precision[],\n",
    "        add COLUMN if not exists home_free_throw_percentage double precision[],\n",
    "        add COLUMN if not exists away_free_throw_percentage double precision[],\n",
    "        add column if not exists home_fouls int[],\n",
    "        add column if not exists away_fouls int[],\n",
    "        add column if not exists home_team_fouls integer,\n",
    "        add column if not exists away_team_fouls integer,\n",
    "        add column if not exists possessions_lead_or_trail integer,\n",
    "        add column if not exists home_ft_bonus bool,\n",
    "        add column if not exists away_ft_bonus bool,\n",
    "        add column if not exists time_left integer,\n",
    "        add column if not exists home_give_foul bool,\n",
    "        add column if not exists away_give_foul bool,\n",
    "        add column if not exists defensive_foul bool,\n",
    "        add column if not exists game_date text;\n",
    "        \"\"\"\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Table play_by_play_q4 altered successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "# connect to database \n",
    "db_config = get_db_config()\n",
    "conn = psycopg2.connect(\n",
    "    database=db_config['database'],\n",
    "    user=db_config['user'],\n",
    "    password=db_config['password'],\n",
    "    host=db_config['host'],\n",
    "    port=db_config['port']\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "print(\"Database connected successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7c2817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated 109 rows for 0022301136\n",
      "updated 150 rows for 0022301137\n",
      "updated 114 rows for 0022301138\n",
      "updated 105 rows for 0022301139\n",
      "updated 193 rows for 0022301140\n",
      "updated 112 rows for 0022301141\n",
      "updated 98 rows for 0022301142\n",
      "updated 122 rows for 0022301143\n",
      "updated 124 rows for 0022301144\n",
      "updated 117 rows for 0022301145\n",
      "updated 131 rows for 0022301146\n",
      "updated 194 rows for 0022301147\n",
      "updated 87 rows for 0022301148\n",
      "updated 105 rows for 0022301149\n",
      "updated 118 rows for 0022301150\n",
      "updated 101 rows for 0022301151\n",
      "updated 100 rows for 0022301152\n",
      "updated 135 rows for 0022301153\n",
      "updated 110 rows for 0022301154\n",
      "updated 110 rows for 0022301155\n",
      "updated 120 rows for 0022301156\n",
      "updated 127 rows for 0022301157\n",
      "updated 118 rows for 0022301158\n",
      "updated 112 rows for 0022301159\n",
      "updated 127 rows for 0022301160\n",
      "updated 110 rows for 0022301161\n",
      "updated 114 rows for 0022301162\n",
      "updated 98 rows for 0022301163\n",
      "updated 139 rows for 0022301164\n",
      "updated 119 rows for 0022301165\n",
      "updated 119 rows for 0022301166\n",
      "updated 77 rows for 0022301167\n",
      "updated 143 rows for 0022301168\n",
      "updated 112 rows for 0022301169\n",
      "updated 96 rows for 0022301170\n",
      "updated 118 rows for 0022301171\n",
      "updated 137 rows for 0022301172\n",
      "updated 114 rows for 0022301173\n",
      "updated 126 rows for 0022301174\n",
      "updated 120 rows for 0022301175\n",
      "updated 119 rows for 0022301176\n",
      "updated 137 rows for 0022301177\n",
      "updated 125 rows for 0022301178\n",
      "updated 102 rows for 0022301179\n",
      "updated 122 rows for 0022301180\n",
      "updated 100 rows for 0022301181\n",
      "updated 113 rows for 0022301182\n",
      "updated 142 rows for 0022301183\n",
      "updated 109 rows for 0022301184\n",
      "updated 109 rows for 0022301185\n",
      "updated 110 rows for 0022301186\n",
      "updated 97 rows for 0022301187\n",
      "updated 102 rows for 0022301188\n",
      "updated 117 rows for 0022301189\n",
      "updated 163 rows for 0022301190\n",
      "updated 102 rows for 0022301191\n",
      "updated 116 rows for 0022301192\n",
      "updated 108 rows for 0022301193\n",
      "updated 108 rows for 0022301194\n",
      "updated 128 rows for 0022301195\n",
      "updated 94 rows for 0022301196\n",
      "updated 102 rows for 0022301197\n",
      "updated 111 rows for 0022301198\n",
      "updated 122 rows for 0022301199\n",
      "updated 130 rows for 0022301200\n",
      "updated 112 rows for 0022301201\n",
      "updated 115 rows for 0022301202\n",
      "updated 113 rows for 0022301203\n",
      "updated 116 rows for 0022301204\n",
      "updated 97 rows for 0022301205\n",
      "updated 106 rows for 0022301206\n",
      "updated 110 rows for 0022301207\n",
      "updated 119 rows for 0022301208\n",
      "updated 126 rows for 0022301209\n",
      "updated 127 rows for 0022301210\n",
      "updated 141 rows for 0022301211\n",
      "updated 121 rows for 0022301212\n",
      "updated 108 rows for 0022301213\n",
      "updated 114 rows for 0022301214\n",
      "updated 123 rows for 0022301215\n",
      "updated 127 rows for 0022301216\n",
      "updated 114 rows for 0022301217\n",
      "updated 139 rows for 0022301218\n",
      "updated 145 rows for 0022301219\n",
      "updated 115 rows for 0022301220\n",
      "updated 104 rows for 0022301221\n",
      "updated 196 rows for 0022301222\n",
      "updated 103 rows for 0022301223\n",
      "updated 162 rows for 0022301224\n",
      "updated 93 rows for 0022301225\n",
      "updated 108 rows for 0022301226\n",
      "updated 125 rows for 0022301227\n",
      "updated 124 rows for 0022301228\n",
      "updated 149 rows for 0022301229\n",
      "updated 112 rows for 0022301230\n",
      "updated 107 rows for 0022400001\n",
      "updated 173 rows for 0022400002\n",
      "updated 133 rows for 0022400003\n",
      "updated 109 rows for 0022400004\n",
      "updated 126 rows for 0022400005\n",
      "updated 126 rows for 0022400006\n",
      "updated 109 rows for 0022400007\n",
      "updated 127 rows for 0022400008\n",
      "updated 99 rows for 0022400009\n",
      "updated 124 rows for 0022400010\n",
      "updated 124 rows for 0022400011\n",
      "updated 138 rows for 0022400012\n",
      "updated 120 rows for 0022400013\n",
      "updated 128 rows for 0022400014\n",
      "updated 112 rows for 0022400015\n",
      "updated 145 rows for 0022400016\n",
      "updated 98 rows for 0022400017\n",
      "updated 138 rows for 0022400018\n",
      "updated 160 rows for 0022400019\n",
      "updated 164 rows for 0022400020\n",
      "updated 122 rows for 0022400021\n",
      "updated 115 rows for 0022400022\n",
      "updated 146 rows for 0022400023\n",
      "updated 121 rows for 0022400024\n",
      "updated 118 rows for 0022400025\n",
      "updated 122 rows for 0022400026\n",
      "updated 106 rows for 0022400027\n",
      "updated 136 rows for 0022400028\n",
      "updated 115 rows for 0022400029\n",
      "updated 125 rows for 0022400030\n",
      "updated 122 rows for 0022400031\n",
      "updated 154 rows for 0022400032\n",
      "updated 148 rows for 0022400033\n",
      "updated 106 rows for 0022400034\n",
      "updated 147 rows for 0022400035\n",
      "updated 115 rows for 0022400036\n",
      "updated 166 rows for 0022400037\n",
      "updated 112 rows for 0022400038\n",
      "updated 127 rows for 0022400039\n",
      "updated 123 rows for 0022400040\n",
      "updated 126 rows for 0022400041\n",
      "updated 125 rows for 0022400042\n",
      "updated 115 rows for 0022400043\n",
      "updated 113 rows for 0022400044\n",
      "updated 123 rows for 0022400045\n",
      "updated 100 rows for 0022400046\n",
      "updated 117 rows for 0022400047\n",
      "updated 130 rows for 0022400048\n",
      "updated 90 rows for 0022400049\n",
      "updated 116 rows for 0022400050\n",
      "updated 109 rows for 0022400051\n",
      "updated 117 rows for 0022400052\n",
      "updated 119 rows for 0022400053\n",
      "updated 130 rows for 0022400054\n",
      "updated 109 rows for 0022400055\n",
      "updated 157 rows for 0022400056\n",
      "updated 134 rows for 0022400057\n",
      "updated 120 rows for 0022400058\n",
      "updated 152 rows for 0022400059\n",
      "updated 105 rows for 0022400060\n",
      "updated 100 rows for 0022400061\n",
      "updated 119 rows for 0022400062\n",
      "updated 134 rows for 0022400063\n",
      "updated 158 rows for 0022400064\n",
      "updated 109 rows for 0022400065\n",
      "updated 129 rows for 0022400066\n",
      "updated 100 rows for 0022400067\n",
      "updated 132 rows for 0022400068\n",
      "updated 137 rows for 0022400069\n",
      "updated 152 rows for 0022400070\n",
      "updated 180 rows for 0022400071\n",
      "updated 135 rows for 0022400072\n",
      "updated 129 rows for 0022400073\n",
      "updated 125 rows for 0022400074\n",
      "updated 122 rows for 0022400075\n",
      "updated 131 rows for 0022400076\n",
      "updated 113 rows for 0022400077\n",
      "updated 137 rows for 0022400078\n",
      "updated 141 rows for 0022400079\n",
      "updated 119 rows for 0022400080\n",
      "updated 125 rows for 0022400081\n",
      "updated 158 rows for 0022400082\n",
      "updated 141 rows for 0022400083\n",
      "updated 117 rows for 0022400084\n",
      "updated 115 rows for 0022400085\n",
      "updated 127 rows for 0022400086\n",
      "updated 120 rows for 0022400087\n",
      "updated 112 rows for 0022400088\n",
      "updated 133 rows for 0022400089\n",
      "updated 151 rows for 0022400090\n",
      "updated 130 rows for 0022400091\n",
      "updated 109 rows for 0022400092\n",
      "updated 123 rows for 0022400093\n",
      "updated 130 rows for 0022400094\n",
      "updated 126 rows for 0022400095\n",
      "updated 109 rows for 0022400096\n",
      "updated 194 rows for 0022400097\n",
      "updated 134 rows for 0022400098\n",
      "updated 120 rows for 0022400099\n",
      "updated 128 rows for 0022400100\n",
      "updated 130 rows for 0022400101\n",
      "updated 133 rows for 0022400102\n",
      "updated 141 rows for 0022400103\n",
      "updated 121 rows for 0022400104\n",
      "updated 125 rows for 0022400105\n",
      "updated 136 rows for 0022400106\n",
      "updated 192 rows for 0022400107\n",
      "updated 123 rows for 0022400108\n",
      "updated 121 rows for 0022400109\n",
      "updated 114 rows for 0022400110\n",
      "updated 132 rows for 0022400111\n",
      "updated 121 rows for 0022400112\n",
      "updated 176 rows for 0022400113\n",
      "updated 128 rows for 0022400114\n",
      "updated 106 rows for 0022400115\n",
      "updated 108 rows for 0022400116\n",
      "updated 145 rows for 0022400117\n",
      "updated 110 rows for 0022400118\n",
      "updated 187 rows for 0022400119\n",
      "updated 105 rows for 0022400120\n",
      "updated 116 rows for 0022400121\n",
      "updated 93 rows for 0022400122\n",
      "updated 147 rows for 0022400123\n",
      "updated 118 rows for 0022400124\n",
      "updated 108 rows for 0022400125\n",
      "updated 131 rows for 0022400126\n",
      "updated 109 rows for 0022400127\n",
      "updated 125 rows for 0022400128\n",
      "updated 111 rows for 0022400129\n",
      "updated 115 rows for 0022400130\n",
      "updated 137 rows for 0022400131\n",
      "updated 140 rows for 0022400132\n",
      "updated 116 rows for 0022400133\n",
      "updated 109 rows for 0022400134\n",
      "updated 114 rows for 0022400135\n",
      "updated 127 rows for 0022400136\n",
      "updated 132 rows for 0022400137\n",
      "updated 132 rows for 0022400138\n",
      "updated 132 rows for 0022400139\n",
      "updated 141 rows for 0022400140\n",
      "updated 102 rows for 0022400141\n",
      "updated 112 rows for 0022400142\n",
      "updated 193 rows for 0022400143\n",
      "updated 182 rows for 0022400144\n",
      "updated 113 rows for 0022400145\n",
      "updated 120 rows for 0022400146\n",
      "updated 138 rows for 0022400147\n",
      "updated 142 rows for 0022400148\n",
      "updated 129 rows for 0022400149\n",
      "updated 116 rows for 0022400150\n",
      "updated 129 rows for 0022400151\n",
      "updated 106 rows for 0022400152\n",
      "updated 135 rows for 0022400153\n",
      "updated 115 rows for 0022400154\n",
      "updated 140 rows for 0022400155\n",
      "updated 126 rows for 0022400156\n",
      "updated 114 rows for 0022400157\n",
      "updated 123 rows for 0022400158\n",
      "updated 135 rows for 0022400159\n",
      "updated 131 rows for 0022400160\n",
      "updated 97 rows for 0022400161\n",
      "updated 110 rows for 0022400162\n",
      "updated 118 rows for 0022400163\n",
      "updated 105 rows for 0022400164\n",
      "updated 99 rows for 0022400165\n",
      "updated 133 rows for 0022400166\n",
      "updated 105 rows for 0022400167\n",
      "updated 106 rows for 0022400168\n",
      "updated 120 rows for 0022400169\n",
      "updated 118 rows for 0022400170\n",
      "updated 130 rows for 0022400171\n",
      "updated 142 rows for 0022400172\n",
      "updated 117 rows for 0022400173\n",
      "updated 121 rows for 0022400174\n",
      "updated 111 rows for 0022400175\n",
      "updated 129 rows for 0022400176\n",
      "updated 136 rows for 0022400177\n",
      "updated 124 rows for 0022400178\n",
      "updated 92 rows for 0022400179\n",
      "updated 109 rows for 0022400180\n",
      "updated 122 rows for 0022400181\n",
      "updated 108 rows for 0022400182\n",
      "updated 136 rows for 0022400183\n",
      "updated 110 rows for 0022400184\n",
      "updated 113 rows for 0022400185\n",
      "updated 104 rows for 0022400186\n",
      "updated 160 rows for 0022400187\n",
      "updated 120 rows for 0022400188\n",
      "updated 118 rows for 0022400189\n",
      "updated 113 rows for 0022400190\n",
      "updated 131 rows for 0022400191\n",
      "updated 120 rows for 0022400192\n",
      "updated 124 rows for 0022400193\n",
      "updated 103 rows for 0022400194\n",
      "updated 129 rows for 0022400195\n",
      "updated 109 rows for 0022400196\n",
      "updated 139 rows for 0022400197\n",
      "updated 126 rows for 0022400198\n",
      "updated 93 rows for 0022400199\n",
      "updated 131 rows for 0022400200\n",
      "updated 147 rows for 0022400201\n",
      "updated 116 rows for 0022400202\n",
      "updated 102 rows for 0022400203\n",
      "updated 132 rows for 0022400204\n",
      "updated 184 rows for 0022400205\n",
      "updated 133 rows for 0022400206\n",
      "updated 139 rows for 0022400207\n",
      "updated 102 rows for 0022400208\n",
      "updated 171 rows for 0022400209\n",
      "updated 134 rows for 0022400210\n",
      "updated 124 rows for 0022400211\n",
      "updated 119 rows for 0022400212\n",
      "updated 132 rows for 0022400213\n",
      "updated 132 rows for 0022400214\n",
      "updated 119 rows for 0022400215\n",
      "updated 107 rows for 0022400216\n",
      "updated 116 rows for 0022400217\n",
      "updated 103 rows for 0022400218\n",
      "updated 113 rows for 0022400219\n",
      "updated 93 rows for 0022400220\n",
      "updated 113 rows for 0022400221\n",
      "updated 123 rows for 0022400222\n",
      "updated 171 rows for 0022400223\n",
      "updated 114 rows for 0022400224\n",
      "updated 152 rows for 0022400225\n",
      "updated 121 rows for 0022400226\n",
      "updated 101 rows for 0022400227\n",
      "updated 99 rows for 0022400228\n",
      "updated 125 rows for 0022400229\n",
      "updated 154 rows for 0022400230\n",
      "updated 106 rows for 0022400231\n",
      "updated 128 rows for 0022400232\n",
      "updated 136 rows for 0022400233\n",
      "updated 136 rows for 0022400234\n",
      "updated 102 rows for 0022400235\n",
      "updated 116 rows for 0022400236\n",
      "updated 117 rows for 0022400237\n",
      "updated 108 rows for 0022400238\n",
      "updated 139 rows for 0022400239\n",
      "updated 114 rows for 0022400240\n",
      "updated 142 rows for 0022400241\n",
      "updated 127 rows for 0022400242\n",
      "updated 110 rows for 0022400243\n",
      "updated 114 rows for 0022400244\n",
      "updated 106 rows for 0022400245\n",
      "updated 99 rows for 0022400246\n",
      "updated 142 rows for 0022400247\n",
      "updated 102 rows for 0022400248\n",
      "updated 107 rows for 0022400249\n",
      "updated 125 rows for 0022400250\n",
      "updated 112 rows for 0022400251\n",
      "updated 92 rows for 0022400252\n",
      "updated 126 rows for 0022400253\n",
      "updated 122 rows for 0022400254\n",
      "updated 106 rows for 0022400255\n",
      "updated 138 rows for 0022400256\n",
      "updated 120 rows for 0022400257\n",
      "updated 129 rows for 0022400258\n",
      "updated 113 rows for 0022400259\n",
      "updated 184 rows for 0022400260\n",
      "updated 129 rows for 0022400261\n",
      "updated 130 rows for 0022400262\n",
      "updated 132 rows for 0022400263\n",
      "updated 95 rows for 0022400264\n",
      "updated 111 rows for 0022400265\n",
      "updated 102 rows for 0022400266\n",
      "updated 125 rows for 0022400267\n",
      "updated 132 rows for 0022400268\n",
      "updated 130 rows for 0022400269\n",
      "updated 113 rows for 0022400270\n",
      "updated 99 rows for 0022400271\n",
      "updated 109 rows for 0022400272\n",
      "updated 173 rows for 0022400273\n",
      "updated 117 rows for 0022400274\n",
      "updated 136 rows for 0022400275\n",
      "updated 117 rows for 0022400276\n",
      "updated 108 rows for 0022400277\n",
      "updated 150 rows for 0022400278\n",
      "updated 119 rows for 0022400279\n",
      "updated 94 rows for 0022400280\n",
      "updated 108 rows for 0022400281\n",
      "updated 125 rows for 0022400282\n",
      "updated 118 rows for 0022400283\n",
      "updated 134 rows for 0022400284\n",
      "updated 132 rows for 0022400285\n",
      "updated 116 rows for 0022400286\n",
      "updated 127 rows for 0022400287\n",
      "updated 112 rows for 0022400288\n",
      "updated 119 rows for 0022400289\n",
      "updated 177 rows for 0022400290\n",
      "updated 124 rows for 0022400291\n",
      "updated 99 rows for 0022400292\n",
      "updated 120 rows for 0022400293\n",
      "updated 106 rows for 0022400294\n",
      "updated 113 rows for 0022400295\n",
      "updated 98 rows for 0022400296\n",
      "updated 121 rows for 0022400297\n",
      "updated 108 rows for 0022400298\n",
      "updated 148 rows for 0022400299\n",
      "updated 133 rows for 0022400300\n",
      "updated 125 rows for 0022400301\n",
      "updated 125 rows for 0022400302\n",
      "updated 108 rows for 0022400303\n",
      "updated 109 rows for 0022400304\n",
      "updated 128 rows for 0022400305\n",
      "updated 145 rows for 0022400306\n",
      "updated 157 rows for 0022400307\n",
      "updated 107 rows for 0022400308\n",
      "updated 119 rows for 0022400309\n",
      "updated 154 rows for 0022400310\n",
      "updated 93 rows for 0022400311\n",
      "updated 106 rows for 0022400312\n",
      "updated 129 rows for 0022400313\n",
      "updated 139 rows for 0022400314\n",
      "updated 104 rows for 0022400315\n",
      "updated 101 rows for 0022400316\n",
      "updated 141 rows for 0022400317\n",
      "updated 103 rows for 0022400318\n",
      "updated 126 rows for 0022400319\n",
      "updated 122 rows for 0022400320\n",
      "updated 104 rows for 0022400321\n",
      "updated 121 rows for 0022400322\n",
      "updated 143 rows for 0022400323\n",
      "updated 129 rows for 0022400324\n",
      "updated 111 rows for 0022400325\n",
      "updated 118 rows for 0022400326\n",
      "updated 94 rows for 0022400327\n",
      "updated 106 rows for 0022400328\n",
      "updated 149 rows for 0022400329\n",
      "updated 134 rows for 0022400330\n",
      "updated 137 rows for 0022400331\n",
      "updated 142 rows for 0022400332\n",
      "updated 101 rows for 0022400333\n",
      "updated 171 rows for 0022400334\n",
      "updated 112 rows for 0022400335\n",
      "updated 104 rows for 0022400336\n",
      "updated 124 rows for 0022400337\n",
      "updated 110 rows for 0022400338\n",
      "updated 105 rows for 0022400339\n",
      "updated 121 rows for 0022400340\n",
      "updated 127 rows for 0022400341\n",
      "updated 108 rows for 0022400342\n",
      "updated 101 rows for 0022400343\n",
      "updated 128 rows for 0022400344\n",
      "updated 136 rows for 0022400345\n",
      "updated 116 rows for 0022400346\n",
      "updated 103 rows for 0022400347\n",
      "updated 108 rows for 0022400348\n",
      "updated 120 rows for 0022400349\n",
      "updated 109 rows for 0022400350\n",
      "updated 103 rows for 0022400351\n",
      "updated 142 rows for 0022400352\n",
      "updated 123 rows for 0022400353\n",
      "updated 129 rows for 0022400354\n",
      "updated 114 rows for 0022400355\n",
      "updated 112 rows for 0022400356\n",
      "updated 94 rows for 0022400357\n",
      "updated 110 rows for 0022400358\n",
      "updated 104 rows for 0022400359\n",
      "updated 142 rows for 0022400360\n",
      "updated 88 rows for 0022400361\n",
      "updated 135 rows for 0022400362\n",
      "updated 121 rows for 0022400363\n",
      "updated 115 rows for 0022400364\n",
      "updated 121 rows for 0022400365\n",
      "updated 108 rows for 0022400366\n",
      "updated 112 rows for 0022400367\n",
      "updated 115 rows for 0022400368\n",
      "updated 113 rows for 0022400369\n",
      "updated 168 rows for 0022400370\n",
      "updated 123 rows for 0022400371\n",
      "updated 112 rows for 0022400372\n",
      "updated 115 rows for 0022400373\n",
      "updated 110 rows for 0022400374\n",
      "updated 129 rows for 0022400375\n",
      "updated 117 rows for 0022400376\n",
      "updated 119 rows for 0022400377\n",
      "updated 101 rows for 0022400378\n",
      "updated 114 rows for 0022400379\n",
      "updated 120 rows for 0022400380\n",
      "updated 117 rows for 0022400381\n",
      "updated 101 rows for 0022400382\n",
      "updated 120 rows for 0022400383\n",
      "updated 108 rows for 0022400384\n",
      "updated 112 rows for 0022400385\n",
      "updated 117 rows for 0022400386\n",
      "updated 129 rows for 0022400387\n",
      "updated 134 rows for 0022400388\n",
      "updated 107 rows for 0022400389\n",
      "updated 178 rows for 0022400390\n",
      "updated 121 rows for 0022400391\n",
      "updated 136 rows for 0022400392\n",
      "updated 107 rows for 0022400393\n",
      "updated 113 rows for 0022400394\n",
      "updated 121 rows for 0022400395\n",
      "updated 92 rows for 0022400396\n",
      "updated 120 rows for 0022400397\n",
      "updated 113 rows for 0022400398\n",
      "updated 129 rows for 0022400399\n",
      "updated 131 rows for 0022400400\n",
      "updated 123 rows for 0022400401\n",
      "updated 97 rows for 0022400402\n",
      "updated 124 rows for 0022400403\n",
      "updated 116 rows for 0022400404\n",
      "updated 92 rows for 0022400405\n",
      "updated 117 rows for 0022400406\n",
      "updated 114 rows for 0022400407\n",
      "updated 138 rows for 0022400408\n",
      "updated 99 rows for 0022400409\n",
      "updated 120 rows for 0022400410\n",
      "updated 109 rows for 0022400411\n",
      "updated 135 rows for 0022400412\n",
      "updated 125 rows for 0022400413\n",
      "updated 137 rows for 0022400414\n",
      "updated 108 rows for 0022400415\n",
      "updated 110 rows for 0022400416\n",
      "updated 121 rows for 0022400417\n",
      "updated 129 rows for 0022400418\n",
      "updated 121 rows for 0022400419\n",
      "updated 121 rows for 0022400420\n",
      "updated 116 rows for 0022400421\n",
      "updated 107 rows for 0022400422\n",
      "updated 107 rows for 0022400423\n",
      "updated 116 rows for 0022400424\n",
      "updated 106 rows for 0022400425\n",
      "updated 128 rows for 0022400426\n",
      "updated 113 rows for 0022400427\n",
      "updated 108 rows for 0022400428\n",
      "updated 177 rows for 0022400429\n",
      "updated 131 rows for 0022400430\n",
      "updated 145 rows for 0022400431\n",
      "updated 119 rows for 0022400432\n",
      "updated 148 rows for 0022400433\n",
      "updated 116 rows for 0022400434\n",
      "updated 110 rows for 0022400435\n",
      "updated 134 rows for 0022400436\n",
      "updated 138 rows for 0022400437\n",
      "updated 126 rows for 0022400438\n",
      "updated 142 rows for 0022400439\n",
      "updated 107 rows for 0022400440\n",
      "updated 136 rows for 0022400441\n",
      "updated 186 rows for 0022400442\n",
      "updated 127 rows for 0022400443\n",
      "updated 123 rows for 0022400444\n",
      "updated 106 rows for 0022400445\n",
      "updated 126 rows for 0022400446\n",
      "updated 127 rows for 0022400447\n",
      "updated 118 rows for 0022400448\n",
      "updated 92 rows for 0022400449\n",
      "updated 126 rows for 0022400450\n",
      "updated 107 rows for 0022400451\n",
      "updated 114 rows for 0022400452\n",
      "updated 178 rows for 0022400453\n",
      "updated 97 rows for 0022400454\n",
      "updated 123 rows for 0022400455\n",
      "updated 114 rows for 0022400456\n",
      "updated 114 rows for 0022400457\n",
      "updated 106 rows for 0022400458\n",
      "updated 117 rows for 0022400459\n",
      "updated 105 rows for 0022400460\n",
      "updated 100 rows for 0022400461\n",
      "updated 111 rows for 0022400462\n",
      "updated 111 rows for 0022400463\n",
      "updated 102 rows for 0022400464\n",
      "updated 136 rows for 0022400465\n",
      "updated 104 rows for 0022400466\n",
      "updated 100 rows for 0022400467\n",
      "updated 112 rows for 0022400468\n",
      "updated 145 rows for 0022400469\n",
      "updated 96 rows for 0022400470\n",
      "updated 108 rows for 0022400471\n",
      "updated 123 rows for 0022400472\n",
      "updated 96 rows for 0022400473\n",
      "updated 143 rows for 0022400474\n",
      "updated 114 rows for 0022400475\n",
      "updated 131 rows for 0022400476\n",
      "updated 116 rows for 0022400477\n",
      "updated 113 rows for 0022400478\n",
      "updated 121 rows for 0022400479\n",
      "updated 110 rows for 0022400480\n",
      "updated 97 rows for 0022400481\n",
      "updated 119 rows for 0022400482\n",
      "updated 113 rows for 0022400483\n",
      "updated 172 rows for 0022400484\n",
      "updated 107 rows for 0022400485\n",
      "updated 102 rows for 0022400486\n",
      "updated 102 rows for 0022400487\n",
      "updated 122 rows for 0022400488\n",
      "updated 117 rows for 0022400489\n",
      "updated 128 rows for 0022400490\n",
      "updated 131 rows for 0022400491\n",
      "updated 99 rows for 0022400492\n",
      "updated 120 rows for 0022400493\n",
      "updated 99 rows for 0022400494\n",
      "updated 121 rows for 0022400495\n",
      "updated 105 rows for 0022400496\n",
      "updated 110 rows for 0022400497\n",
      "updated 136 rows for 0022400498\n",
      "updated 120 rows for 0022400499\n",
      "updated 140 rows for 0022400500\n",
      "updated 213 rows for 0022400501\n",
      "updated 117 rows for 0022400502\n",
      "updated 110 rows for 0022400503\n",
      "updated 94 rows for 0022400504\n",
      "updated 129 rows for 0022400505\n",
      "updated 114 rows for 0022400506\n",
      "updated 113 rows for 0022400507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing game 0022400508: HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)\n",
      "Detected connection issue, restarting notebook...\n",
      "Database connections closed\n",
      "Re-running notebook via Papermill: ..\\api_data\\scraping_playbyplay.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  50%|█████     | 1/2 [00:03<00:03,  3.58s/cell]c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "Executing:   0%|          | 0/2 [00:00<?, ?cell/s]\n",
      "Executing:  50%|█████     | 1/2 [00:03<00:03,  3.37s/cell]\n",
      "c:\\Users\\lagis\\OneDrive\\Documents\\GitHub\\IntentionalFoulPrediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "\n",
      "Executing:   0%|          | 0/2 [00:00<?, ?cell/s]\n",
      "\n",
      "Executing:  50%|█████     | 1/2 [00:03<00:03,  3.78s/cell]\n",
      "\n",
      "Executing: 100%|██████████| 2/2 [05:29<00:00, 193.07s/cell]\n",
      "\n",
      "Executing: 100%|██████████| 2/2 [05:29<00:00, 164.75s/cell]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Executing: 100%|██████████| 2/2 [14:16<00:00, 503.04s/cell]\n",
      "Executing: 100%|██████████| 2/2 [14:16<00:00, 428.26s/cell]\n",
      "\n",
      "\n",
      "Executing: 100%|██████████| 2/2 [21:40<00:00, 650.49s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook run complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# all configurations for nba api requests\n",
    "CONFIGS = {\n",
    "    'api_call_sleep' : .600,\n",
    "    'batch_size' : 1000,\n",
    "    'seasons' : [\n",
    "        '2024-25',\n",
    "        '2023-24',\n",
    "        '2022-23',\n",
    "        '2021-22',\n",
    "        '2020-21',\n",
    "        '2019-20',\n",
    "        '2018-19',\n",
    "        '2017-18',\n",
    "        '2016-17',\n",
    "        '2015-16',\n",
    "        '2014-15',\n",
    "    ],\n",
    "    'season_types' : ['Regular Season', 'Playoffs'],\n",
    "    'min_quarter': 4,\n",
    "}\n",
    "\n",
    "NOTEBOOK_PATH = \"..\\\\api_data\\\\scraping_playbyplay.ipynb\"\n",
    "\n",
    "# Create SQLAlchemy engine for pandas to_sql functionality\n",
    "CONNECTION_STR = (\n",
    "    f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}\"\n",
    "    f\"@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    ")\n",
    "ENGINE = create_engine(CONNECTION_STR)\n",
    "\n",
    "GAME_IDS =[]\n",
    "\n",
    "def restart_run_notebook(nb_path=NOTEBOOK_PATH):\n",
    "    \"\"\"\n",
    "    Rerunning the notebook because of API call bottleneck:\n",
    "    HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)\n",
    "    There are probably better solutions but resetting the kernel was the solution that worked out for me\n",
    "    \"\"\"\n",
    "    print(f\"Re-running notebook via Papermill: {nb_path}\")\n",
    "    pm.execute_notebook(\n",
    "        nb_path,       \n",
    "        nb_path,           \n",
    "        log_output=True,\n",
    "        timeout=None\n",
    "    )\n",
    "    print(\"Notebook run complete.\")\n",
    "\n",
    "def fetch_game_ids():\n",
    "    # Get game IDs directly from NBA API\n",
    "    print(\"Fetching game IDs from NBA API...\")\n",
    "    for season in CONFIGS['seasons']:\n",
    "        for season_type in CONFIGS['season_types']:\n",
    "            print(f\"Fetching {season} {season_type} games\")\n",
    "            try: \n",
    "                gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "                    season_nullable=season,\n",
    "                    season_type_nullable=season_type\n",
    "                )\n",
    "                time.sleep(CONFIGS['api_call_sleep'])\n",
    "                season_games_df = gamefinder.get_data_frames()[0]\n",
    "                season_game_ids = season_games_df['GAME_ID']\n",
    "                season_game_ids = season_game_ids[season_game_ids.astype(str).str.startswith(('002','004'))].unique().tolist()\n",
    "                GAME_IDS.extend(season_game_ids)\n",
    "                print(f\"Found {len(season_game_ids)} games for {season} {season_type}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {season} {season_type}: {e}\")\n",
    "        time.sleep(CONFIGS['api_call_sleep'])\n",
    "    return list(set(GAME_IDS))\n",
    "\n",
    "def fetch_playbyplay_to_database():\n",
    "    # Query existing game IDs from the database\n",
    "    print(\"Checking for existing games in database...\")\n",
    "    existing_games_query = \"SELECT DISTINCT game_id FROM play_by_play_q4\"\n",
    "    existing_games_df = pd.read_sql(existing_games_query, ENGINE)\n",
    "    existing_game_ids = set(existing_games_df['game_id'].astype(str).tolist() if not existing_games_df.empty else [])\n",
    "    print(f\"Found {len(existing_game_ids)} existing games in database\")\n",
    "    season_patterns = [f\"game_id LIKE '0021{i}%%'\" for i in range(4, 10)] + [f\"game_id LIKE '0022{i}%%'\" for i in range(0, 5)] + [f\"game_id LIKE '0041{i}%%'\" for i in range(4, 10)] + [f\"game_id LIKE '0042{i}%%'\" for i in range(0, 5)]\n",
    "    season_conditions = \" OR \".join(season_patterns)\n",
    "    specific_season_query = f\"SELECT DISTINCT game_id FROM play_by_play_q4 WHERE {season_conditions}\"\n",
    "    specific_df = pd.read_sql(specific_season_query, ENGINE)\n",
    "    specific_id = set(specific_df['game_id'].astype(str).tolist() if not specific_df.empty else [])\n",
    "    print(f\"Found {len(specific_id)} existing games from 2014-15 through 2024-25 seasons\")\n",
    "\n",
    "    # Filter for only new game IDs\n",
    "    new_game_ids = [game_id for game_id in GAME_IDS if game_id not in existing_game_ids]\n",
    "    print(f\"Processing {len(new_game_ids)} new games\")\n",
    "        \n",
    "    # Fetch and insert play-by-play data for each game\n",
    "    for i, game_id in enumerate(new_game_ids):\n",
    "        try:\n",
    "            print(f\"[{i+1}/{len(new_game_ids)}] Fetching for {game_id}\")\n",
    "            pbp = playbyplayv2.PlayByPlayV2(game_id=game_id)\n",
    "            time.sleep(CONFIGS['api_call_sleep'])\n",
    "            df = pbp.get_data_frames()[0]\n",
    "            df = df[df[\"PERIOD\"] >= CONFIGS['min_quarter']]  # Filter for 4th/ot quarter only\n",
    "                \n",
    "            if not df.empty:\n",
    "                # Convert all column names to lowercase to match PostgreSQL default behavior\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "                    \n",
    "                # Check which columns from df match our table schema\n",
    "                cursor.execute(\"SELECT * FROM play_by_play_q4 LIMIT 0\")\n",
    "                colnames = [desc[0].lower() for desc in cursor.description]\n",
    "                    \n",
    "                # Only keep columns that exist in our schema\n",
    "                df_filtered = df[[col for col in df.columns if col in colnames]]\n",
    "                    \n",
    "                # Use if_exists='append' to add to existing table\n",
    "                df_filtered.to_sql(\"play_by_play_q4\", ENGINE, if_exists=\"append\", index=False, method='multi', chunksize=CONFIGS['batch_size'])\n",
    "                print(f\"Added {len(df_filtered)} plays for game {game_id}\")\n",
    "            else:\n",
    "                print(f\"No 4th quarter data found for game {game_id}\")\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(f\"Error on {game_id}: {e}\")\n",
    "            if \"HTTPSConnectionPool\" in str(e):\n",
    "                print(\"Detected connection issue, restarting notebook\")\n",
    "                close_db()\n",
    "                restart_run_notebook(NOTEBOOK_PATH)\n",
    "                return       \n",
    "            # adds the game id anyways\n",
    "            if \"duplicate key value violates unique constraint\" in str(e):\n",
    "                with ENGINE.begin() as conn:\n",
    "                    for _, row in df_filtered.iterrows():\n",
    "                        row_dict = row.to_dict()\n",
    "                        columns = row_dict.keys()\n",
    "\n",
    "                        insert_cols = \", \".join(columns)\n",
    "                        placeholders = \", \".join([f\":{col}\" for col in columns])\n",
    "                        update_cols = [f\"{col} = EXCLUDED.{col}\" for col in columns if col not in (\"game_id\", \"eventnum\")]\n",
    "                        update_clause = \", \".join(update_cols)\n",
    "\n",
    "                        query = text(f\"\"\"\n",
    "                            INSERT INTO play_by_play_q4 ({insert_cols})\n",
    "                            VALUES ({placeholders})\n",
    "                            ON CONFLICT (game_id, eventnum)\n",
    "                            DO UPDATE SET {update_clause}\n",
    "                        \"\"\")\n",
    "\n",
    "                        conn.execute(query, row_dict)\n",
    "                        print(\"game updated in database\")\n",
    "    print(\"Data import completed\")\n",
    "\n",
    "def fetch_players_on_court():\n",
    "    existing_games_query = \"\"\"SELECT game_id\n",
    "                            FROM public.play_by_play_q4\n",
    "                            WHERE period = 4\n",
    "                            GROUP BY game_id\n",
    "                            HAVING COUNT(*) = COUNT(*) FILTER (\n",
    "                                WHERE home_players IS NULL AND away_players IS NULL\n",
    "                            );\n",
    "                            \"\"\"\n",
    "    existing_games_df = pd.read_sql(existing_games_query, ENGINE)\n",
    "    conn = ENGINE.raw_connection()  # Get the connection\n",
    "    cursor = conn.cursor()          # Get cursor from connection\n",
    "    for _, game_row in existing_games_df.iterrows():\n",
    "        try :\n",
    "            home_sub, away_sub, period_start, period_end = find_substitutions(str(game_row['game_id']))\n",
    "            home_lineup = get_starting_lineup_fourth(home_sub, period_start)\n",
    "            away_lineup = get_starting_lineup_fourth(away_sub, period_start)\n",
    "            print(f\"GAME_ID: {game_row['game_id']}\")\n",
    "            print(f\"HOME: {home_lineup}\")\n",
    "            print(f\"AWAY: {away_lineup}\")\n",
    "            if len(home_lineup) == 5 and len(away_lineup) == 5:\n",
    "                update_query = \"\"\"\n",
    "                        UPDATE play_by_play_q4\n",
    "                        SET home_players = %s, away_players = %s\n",
    "                        WHERE game_id = %s AND eventnum = %s \n",
    "                        \"\"\"\n",
    "                cursor.execute(update_query, (home_lineup, away_lineup, str(game_row['game_id']), int(period_start)))\n",
    "                conn.commit()\n",
    "                # go through lineup changes after the first start\n",
    "                for event_num in range(period_start+1, period_end+1):\n",
    "                    for player_id, sub_events in home_sub.items():\n",
    "                        q4 = sub_events.get(4, {'in': [], 'out': []})\n",
    "                        for event in q4['in']:\n",
    "                            if event == event_num:\n",
    "                                home_lineup.append(player_id)\n",
    "                        for event in q4['out']:\n",
    "                            if event == event_num:\n",
    "                                home_lineup.remove(player_id)\n",
    "                    for player_id, sub_events in away_sub.items():\n",
    "                        q4 = sub_events.get(4, {'in': [], 'out': []})\n",
    "                        for event in q4['in']:\n",
    "                            if event == event_num:\n",
    "                                away_lineup.append(player_id)\n",
    "                        for event in q4['out']:\n",
    "                            if event == event_num:\n",
    "                                away_lineup.remove(player_id)\n",
    "                    update_query = \"\"\"\n",
    "                        UPDATE play_by_play_q4\n",
    "                        SET home_players = %s, away_players = %s\n",
    "                        WHERE game_id = %s AND eventnum = %s\n",
    "                    \"\"\"\n",
    "                    cursor.execute(update_query, (home_lineup, away_lineup, str(game_row['game_id']), int(event_num)))\n",
    "                    conn.commit()\n",
    "            else:\n",
    "                home_lineup = [0,0,0,0,0]\n",
    "                away_lineup = [0,0,0,0,0]\n",
    "                update_query = \"\"\"\n",
    "                        UPDATE play_by_play_q4\n",
    "                        SET home_players = %s, away_players = %s\n",
    "                        WHERE game_id = %s AND eventnum = %s\n",
    "                        \"\"\"\n",
    "                cursor.execute(update_query, (home_lineup, away_lineup, str(game_row['game_id']), int(period_start)))\n",
    "                conn.commit()\n",
    "                for event_num in range(period_start+1, period_end+1):\n",
    "                    update_query = \"\"\"\n",
    "                        UPDATE play_by_play_q4\n",
    "                        SET home_players = %s, away_players = %s\n",
    "                        WHERE game_id = %s AND eventnum = %s\n",
    "                    \"\"\"\n",
    "                    cursor.execute(update_query, (home_lineup, away_lineup, str(game_row['game_id']), int(event_num)))\n",
    "                    conn.commit()\n",
    "                print(\"starting lineup was not successful\")\n",
    "        except Exception as e:\n",
    "            if \"HTTPSConnectionPool\" in str(e):\n",
    "                print(\"Detected connection issue, restarting notebook\")\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "                restart_run_notebook(NOTEBOOK_PATH)\n",
    "                return\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print('data import completed')\n",
    "\n",
    "def remove_games():\n",
    "    with ENGINE.begin() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            DELETE FROM play_by_play_q4\n",
    "            WHERE NOT (\n",
    "                game_id LIKE '0021%' OR \n",
    "                game_id LIKE '0022%' OR \n",
    "                game_id LIKE '0041%' OR \n",
    "                game_id LIKE '0042%'\n",
    "            );\n",
    "        \"\"\"))\n",
    "    print(\"Deleted all games not starting with 0021, 0022, 0041, or 0042\")\n",
    "\n",
    "def find_substitutions(game_id):\n",
    "    \"\"\"\n",
    "    will refactor this and just get 4th quarter and beyond plays only\n",
    "    \"\"\"\n",
    "    pbp = playbyplayv2.PlayByPlayV2(game_id)\n",
    "    time.sleep(CONFIGS['api_call_sleep'])\n",
    "    all_plays_df = pbp.get_data_frames()[0]\n",
    "    all_plays_df = all_plays_df.sort_values('EVENTNUM')\n",
    "    fourth_quarter = all_plays_df[all_plays_df['PERIOD'] == 4]\n",
    "    fourth_quarter_start = fourth_quarter.sort_values('EVENTNUM').iloc[0]['EVENTNUM']\n",
    "    fourth_quarter_end = fourth_quarter['EVENTNUM'].max()\n",
    "    home_team,away_team = fetch_players_with_minutes(game_id)\n",
    "\n",
    "    player_subs_home = {}\n",
    "    player_subs_away = {}\n",
    "    # adds mapping for all players home/away\n",
    "    for player_id in home_team:\n",
    "        player_subs_home[player_id] = {\n",
    "            4: {'in': [], 'out': []}\n",
    "        }\n",
    "    for player_id in away_team:\n",
    "        player_subs_away[player_id] = {\n",
    "            4: {'in': [], 'out': []}\n",
    "        }\n",
    "    for _, row in fourth_quarter.iterrows():\n",
    "        if row['EVENTMSGTYPE'] == 8:  # Substitution\n",
    "            player_out = row['PLAYER1_ID']\n",
    "            player_in = row['PLAYER2_ID']\n",
    "            event_num = row['EVENTNUM']\n",
    "            quarter = row['PERIOD']\n",
    "\n",
    "            if player_in in home_team:\n",
    "                team_subs = player_subs_home\n",
    "            else:\n",
    "                team_subs = player_subs_away\n",
    "            # adds the out/in event number data to the players involved in the substitution\n",
    "            for player_id, direction in [(player_out, 'out'), (player_in, 'in')]:\n",
    "                team_subs[player_id][quarter][direction].append(event_num)\n",
    "    return player_subs_home, player_subs_away, fourth_quarter_start, fourth_quarter_end\n",
    "\n",
    "def get_starting_lineup_fourth(sub_data, event_index):\n",
    "    \"\"\"\n",
    "    Gets the starting lineup through finding substitution timestamps\n",
    "    \"\"\"\n",
    "    starting_lineup = []\n",
    "\n",
    "    for player_id, quarters in sub_data.items():\n",
    "        q4 = quarters.get(4, {'in': [], 'out': []})\n",
    "        print(f\"{player_id} : {q4}\")\n",
    "        if len(q4['in']) == 0 and len(q4['out']) == 0:\n",
    "            starting_lineup.append(player_id)\n",
    "        elif len(q4['in']) == 0 and len(q4['out']) > 0:\n",
    "            if q4['out'][0] > event_index:\n",
    "                starting_lineup.append(player_id)\n",
    "        elif len(q4['in']) > 0 and len(q4['out']) > 0:\n",
    "            if q4['out'][0] > event_index and q4['out'][0] < q4['in'][0]:\n",
    "                starting_lineup.append(player_id)\n",
    "    return starting_lineup\n",
    "\n",
    "def fetch_players_with_minutes(game_id):\n",
    "    \"\"\"\n",
    "    Finds all players who played in the 4th quarter. \n",
    "    Will need to refactor for overtime periods.\n",
    "    \"\"\"\n",
    "    box = boxscoretraditionalv3.BoxScoreTraditionalV3(\n",
    "        game_id=game_id,\n",
    "        start_period=4,\n",
    "        range_type=1,\n",
    "        end_period=4\n",
    "    )\n",
    "    time.sleep(CONFIGS['api_call_sleep'])\n",
    "    \n",
    "    # Extract player stats \n",
    "    box_dict = box.get_dict()\n",
    "    \n",
    "    all_home_players = box_dict['boxScoreTraditional']['homeTeam']['players']\n",
    "    all_away_players = box_dict['boxScoreTraditional']['awayTeam']['players']\n",
    "    \n",
    "    home_team_players = [\n",
    "        player['personId'] \n",
    "        for player in all_home_players \n",
    "        if player.get('statistics', {}).get('minutes')\n",
    "    ]\n",
    "    \n",
    "    away_team_players = [\n",
    "        player['personId'] \n",
    "        for player in all_away_players \n",
    "        if player.get('statistics', {}).get('minutes')\n",
    "    ]\n",
    "    return home_team_players, away_team_players\n",
    "\n",
    "def fetch_three_point_and_free_throw_percentages(): \n",
    "    query = \"\"\"\n",
    "    SELECT game_id \n",
    "    FROM public.play_by_play_q4\n",
    "    WHERE period = 4 \n",
    "    GROUP BY game_id \n",
    "    HAVING COUNT(*) FILTER (\n",
    "        WHERE period = 4\n",
    "        AND home_players IS NOT NULL \n",
    "        AND away_players IS NOT NULL \n",
    "        AND home_3pt_percentage IS NULL \n",
    "        AND away_3pt_percentage IS NULL \n",
    "        AND home_free_throw_percentage IS NULL \n",
    "        AND away_free_throw_percentage IS NULL\n",
    "        ) = COUNT(*) FILTER (\n",
    "            WHERE period = 4\n",
    "            AND home_players IS NOT NULL \n",
    "            AND away_players IS NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    existing_games_df = pd.read_sql(query, ENGINE)\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    for _, game_row in existing_games_df.iterrows():\n",
    "        try: \n",
    "            game_id = game_row['game_id']\n",
    "            year = game_id[3:5]\n",
    "\n",
    "            game_query = \"\"\"\n",
    "            SELECT home_players, away_players, eventnum \n",
    "            FROM public.play_by_play_q4\n",
    "            WHERE game_id = %s and period = 4\n",
    "            ORDER BY eventnum ASC\n",
    "            \"\"\"\n",
    "            cursor.execute(game_query, (game_id,))\n",
    "            result = cursor.fetchall()\n",
    "\n",
    "            home_players = [row[0] for row in result]\n",
    "            away_players = [row[1] for row in result]\n",
    "            eventnum_list = [row[2] for row in result]\n",
    "            # Flatten all player IDs and get unique ones\n",
    "            unique_player_ids = set(\n",
    "                player_id\n",
    "                for lineup in home_players + away_players\n",
    "                for player_id in lineup if player_id is not None\n",
    "            )\n",
    "            # Fetch 3PT and FT% for each unique player\n",
    "            player_pct = {\n",
    "                player_id: get_percentages(str(player_id), year)\n",
    "                for player_id in unique_player_ids\n",
    "            }\n",
    "\n",
    "            for i in range(len(eventnum_list)):\n",
    "                home_3pt_percent = []\n",
    "                home_ft_percent = []\n",
    "                away_3pt_percent = []\n",
    "                away_ft_percent = []\n",
    "\n",
    "                for player_id in home_players[i]:\n",
    "                    if player_id in player_pct:\n",
    "                        fg3_pct, ft_pct = player_pct[player_id]\n",
    "                        home_3pt_percent.append(fg3_pct)\n",
    "                        home_ft_percent.append(ft_pct)\n",
    "\n",
    "                for player_id in away_players[i]:\n",
    "                    if player_id in player_pct:\n",
    "                        fg3_pct, ft_pct = player_pct[player_id]\n",
    "                        away_3pt_percent.append(fg3_pct)\n",
    "                        away_ft_percent.append(ft_pct)\n",
    "\n",
    "                complete_query = \"\"\"\n",
    "                UPDATE public.play_by_play_q4 \n",
    "                SET home_3pt_percentage = %s,\n",
    "                    away_3pt_percentage = %s,\n",
    "                    home_free_throw_percentage = %s,\n",
    "                    away_free_throw_percentage = %s\n",
    "                WHERE game_id = %s AND eventnum = %s\n",
    "                \"\"\"\n",
    "                cursor.execute(complete_query, (\n",
    "                    home_3pt_percent, away_3pt_percent,\n",
    "                    home_ft_percent, away_ft_percent,\n",
    "                    game_id, eventnum_list[i]\n",
    "                ))\n",
    "                conn.commit()\n",
    "\n",
    "            print(f\"Successfully added 3PT and FT percentages for game {game_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing game {game_id}: {e}\")\n",
    "            if \"HTTPSConnectionPool\" in str(e):\n",
    "                print(\"Detected connection issue, restarting notebook...\")\n",
    "                close_db()\n",
    "                restart_run_notebook(NOTEBOOK_PATH)\n",
    "                return\n",
    "\n",
    "    close_db()\n",
    "    print(\"Data import for all eligible games completed.\")\n",
    "\n",
    "def fetch_play_fouls():\n",
    "    query = \"\"\"\n",
    "    SELECT game_id \n",
    "    FROM public.play_by_play_q4\n",
    "    WHERE period = 4 \n",
    "    GROUP BY game_id \n",
    "    HAVING COUNT(*) FILTER (\n",
    "        WHERE period = 4\n",
    "        AND home_players IS NOT NULL \n",
    "        AND away_players IS NOT NULL \n",
    "        AND home_fouls IS NULL \n",
    "        AND away_fouls IS NULL\n",
    "        ) = COUNT(*) FILTER (\n",
    "            WHERE period = 4\n",
    "            AND home_players IS NOT NULL \n",
    "            AND away_players IS NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    existing_games_df = pd.read_sql(query, ENGINE)\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    for _, game_row in existing_games_df.iterrows():\n",
    "        try: \n",
    "            game_id = game_row['game_id']\n",
    "            pbp = playbyplayv2.PlayByPlayV2(game_id)\n",
    "            time.sleep(CONFIGS['api_call_sleep'])\n",
    "            all_plays_df = pbp.get_data_frames()[0]\n",
    "            all_plays_df = all_plays_df.sort_values('EVENTNUM')\n",
    "            game_query = \"\"\"\n",
    "                SELECT home_players, away_players, eventnum \n",
    "                FROM public.play_by_play_q4\n",
    "                WHERE game_id = %s and period = 4\n",
    "                ORDER BY eventnum ASC\n",
    "                \"\"\"\n",
    "            cursor.execute(game_query, (game_id,))\n",
    "            result = cursor.fetchall()\n",
    "            home_players = [row[0] for row in result]\n",
    "            away_players = [row[1] for row in result]\n",
    "            # Flatten all player IDs and get unique ones\n",
    "            unique_player_dict = {\n",
    "                player_id: 0\n",
    "                for lineup in home_players + away_players\n",
    "                for player_id in lineup if player_id is not None\n",
    "            }\n",
    "            lineup_counter = 0\n",
    "            for _,play in all_plays_df.iterrows():\n",
    "                home_fouls = []\n",
    "                away_fouls = []\n",
    "                if play['EVENTMSGTYPE'] == 6 and play['PLAYER1_ID'] in unique_player_dict:\n",
    "                    unique_player_dict[play['PLAYER1_ID']] += 1 \n",
    "                if play['PERIOD'] == 4:\n",
    "                    for player_id in home_players[lineup_counter]:\n",
    "                        home_fouls.append(unique_player_dict[player_id])\n",
    "                    for player_id in away_players[lineup_counter]:\n",
    "                        away_fouls.append(unique_player_dict[player_id])\n",
    "                    complete_query = \"\"\"\n",
    "                        UPDATE public.play_by_play_q4 \n",
    "                        SET home_fouls = %s,\n",
    "                            away_fouls = %s\n",
    "                        WHERE game_id = %s AND eventnum = %s\n",
    "                        \"\"\"\n",
    "                    cursor.execute(complete_query, (\n",
    "                        home_fouls, away_fouls,\n",
    "                        game_id, play['EVENTNUM']\n",
    "                    ))\n",
    "                    conn.commit()\n",
    "                    lineup_counter += 1\n",
    "            print(f\"Successfully added home and away fouls for game {game_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing game {game_id}: {e}\")\n",
    "            if \"HTTPSConnectionPool\" in str(e):\n",
    "                print(\"Detected connection issue, restarting notebook...\")\n",
    "                close_db()\n",
    "                restart_run_notebook(NOTEBOOK_PATH)\n",
    "                return\n",
    "    close_db()\n",
    "    print(\"Data import for all eligible games completed.\")\n",
    "    return\n",
    "\n",
    "def team_fouls():\n",
    "    query = \"\"\"\n",
    "    SELECT game_id \n",
    "    FROM public.play_by_play_q4\n",
    "    WHERE period = 4 \n",
    "    GROUP BY game_id \n",
    "    HAVING COUNT(*) FILTER (\n",
    "        WHERE period = 4\n",
    "        AND home_players IS NOT NULL \n",
    "        AND away_players IS NOT NULL \n",
    "        AND home_team_fouls IS NULL \n",
    "        AND away_team_fouls IS NULL\n",
    "        ) = COUNT(*) FILTER (\n",
    "            WHERE period = 4\n",
    "            AND home_players IS NOT NULL \n",
    "            AND away_players IS NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    existing_games_df = pd.read_sql(query, ENGINE)\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    for _, game_row in existing_games_df.iterrows():\n",
    "        try:\n",
    "            game_id = game_row['game_id']\n",
    "            play_by_play = playbyplayv2.PlayByPlayV2(game_id=game_id)\n",
    "            time.sleep(CONFIGS['api_call_sleep'])\n",
    "            plays = play_by_play.get_data_frames()[0]\n",
    "            plays = plays[plays[\"PERIOD\"] == 4]\n",
    "            plays = plays.sort_values(\"EVENTNUM\")\n",
    "            home_team_fouls = 0\n",
    "            away_team_fouls = 0\n",
    "            for _, play in plays.iterrows():\n",
    "                defensive_foul = False\n",
    "                if play['EVENTMSGTYPE'] == 6:\n",
    "                    if play['HOMEDESCRIPTION'] and 'OFF.FOUL' not in play['HOMEDESCRIPTION']:\n",
    "                        home_team_fouls += 1\n",
    "                        defensive_foul = True\n",
    "                    if play['VISITORDESCRIPTION'] and 'OFF.FOUL' not in play['VISITORDESCRIPTION']:\n",
    "                        away_team_fouls += 1\n",
    "                        defensive_foul = True\n",
    "                finish_query = \"\"\"\n",
    "                        UPDATE public.play_by_play_q4 \n",
    "                        SET home_team_fouls = %s,\n",
    "                            away_team_fouls = %s,\n",
    "                            defensive_foul = %s\n",
    "                        WHERE game_id = %s AND eventnum = %s\n",
    "                        \"\"\"\n",
    "                cursor.execute(finish_query, (\n",
    "                        home_team_fouls, away_team_fouls,defensive_foul,\n",
    "                        game_id, play['EVENTNUM']\n",
    "                    ))\n",
    "                conn.commit()\n",
    "            print(f\"Successfully added home and away fouls for game {game_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing game {game_id}: {e}\")\n",
    "            if \"HTTPSConnectionPool\" in str(e):\n",
    "                print(\"Detected connection issue, restarting notebook...\")\n",
    "                close_db()\n",
    "                restart_run_notebook(NOTEBOOK_PATH)\n",
    "                return\n",
    "    close_db()\n",
    "    print(\"Data import for all eligible games completed.\")\n",
    "    return\n",
    "\n",
    "def get_percentages(player_id,year):\n",
    "    dashboard = playerdashboardbyyearoveryear.PlayerDashboardByYearOverYear(player_id=player_id).get_data_frames()[1]\n",
    "    time.sleep(CONFIGS['api_call_sleep'])\n",
    "    dashboard = dashboard[['GROUP_VALUE', 'FTM', 'FTA', 'FG3A', 'FG3M']]\n",
    "    dashboard = dashboard.sort_values(by='GROUP_VALUE', ascending=True)\n",
    "    ft_makes = 0\n",
    "    ft_attempts = 0\n",
    "    three_makes = 0\n",
    "    three_attempts = 0\n",
    "    average_3pt_pct = 0\n",
    "    average_ft_pct = 0\n",
    "    for _, row in dashboard.iterrows():\n",
    "        season_year = int(row['GROUP_VALUE'][5:7])  # e.g., '2023-24' → '24'\n",
    "        if season_year > int(year):\n",
    "            break\n",
    "        else:\n",
    "            ft_makes += int(row['FTM'])\n",
    "            ft_attempts += int(row['FTA'])\n",
    "            three_makes += int(row['FG3M'])\n",
    "            three_attempts += int(row['FG3A'])\n",
    "    if ft_attempts > 0:\n",
    "        average_ft_pct = ft_makes/ft_attempts\n",
    "    if three_attempts > 0:\n",
    "        average_3pt_pct = three_makes/three_attempts  \n",
    "    return (round(average_3pt_pct,3), round(average_ft_pct,3))\n",
    "\n",
    "def num_of_possessions_down():\n",
    "    db_query = \"\"\"\n",
    "        SELECT game_id, eventnum, scoremargin \n",
    "        FROM play_by_play_q4 \n",
    "        GROUP BY game_id, eventnum\n",
    "    \"\"\"\n",
    "    possessions_db = pd.read_sql(db_query, ENGINE)\n",
    "\n",
    "    updates = []\n",
    "    current_game_id = None\n",
    "    current_game_possession = 0\n",
    "    for _, play in possessions_db.iterrows():\n",
    "        score_margin = play['scoremargin']\n",
    "        game_id = play['game_id']\n",
    "        if game_id != current_game_id:\n",
    "            current_game_id = game_id\n",
    "            current_game_possession = 0\n",
    "        if score_margin and 'TIE' not in str(score_margin):\n",
    "            current_possession = math.ceil(int(score_margin) / 3)\n",
    "            current_game_possession = current_possession\n",
    "        if score_margin and 'TIE' in str(score_margin):\n",
    "            current_game_possession = 0\n",
    "        updates.append((current_game_possession, play['game_id'], play['eventnum']))\n",
    "\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    update_query = \"\"\"\n",
    "        UPDATE play_by_play_q4\n",
    "        SET possessions_lead_or_trail = %s\n",
    "        WHERE game_id = %s AND eventnum = %s\n",
    "    \"\"\"\n",
    "    execute_batch(cursor, update_query, updates, page_size=1000)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"Updated {len(updates)} rows successfully.\")\n",
    "\n",
    "def foul_bonus():\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    query = \"\"\"\n",
    "        select game_id, eventnum, home_team_fouls, away_team_fouls, pctimestring from play_by_play_q4\n",
    "        group by game_id, eventnum\n",
    "    \"\"\" \n",
    "    fouls_db = pd.read_sql(query, ENGINE)\n",
    "    update_batch = []\n",
    "    current_game_id = None\n",
    "    away_bonus = False\n",
    "    home_bonus = False\n",
    "    home_foul_to_give = True\n",
    "    away_foul_to_give = True\n",
    "    two_minute_period = str_time_to_timedelta(\"2:00\")\n",
    "    for _, play in fouls_db.iterrows():\n",
    "        current_time_of_play = str_time_to_timedelta(play['pctimestring'])\n",
    "        if current_game_id != play['game_id']:\n",
    "            current_game_id = play['game_id']\n",
    "            away_bonus = False\n",
    "            home_bonus = False \n",
    "            home_foul_to_give = True\n",
    "            away_foul_to_give = True\n",
    "        home_fouls = play['home_team_fouls']\n",
    "        away_fouls = play['away_team_fouls']\n",
    "        # 4 team fouls are allowed or 1 give-foul within 2-minutes of the 4th quarter ending before bonus\n",
    "        if home_fouls:\n",
    "            if home_fouls > 4:\n",
    "                home_bonus = True\n",
    "            elif current_time_of_play <= two_minute_period:\n",
    "                if not home_bonus and not home_foul_to_give:\n",
    "                    home_bonus = True\n",
    "                elif home_foul_to_give:\n",
    "                    home_foul_to_give = False\n",
    "        if away_fouls:\n",
    "            if away_fouls > 4:\n",
    "                away_bonus = True\n",
    "            elif current_time_of_play <= two_minute_period:\n",
    "                if not away_bonus and not away_foul_to_give:\n",
    "                    away_bonus = True\n",
    "                elif away_foul_to_give:\n",
    "                    away_foul_to_give = False\n",
    "        update_batch.append((home_bonus, away_bonus, home_foul_to_give, away_foul_to_give, play['game_id'], play['eventnum']))\n",
    "    update_query = \"\"\"\n",
    "        update play_by_play_q4 \n",
    "        set home_ft_bonus = %s, away_ft_bonus = %s, home_give_foul = %s, away_give_foul = %s\n",
    "        where game_id = %s and eventnum = %s\n",
    "    \"\"\"\n",
    "    execute_batch(cursor, update_query, update_batch, page_size=1000)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"Updated all rows successfully\")\n",
    "\n",
    "def convert_time():\n",
    "    query = \"\"\"\n",
    "        select game_id, eventnum, pctimestring from play_by_play_q4\n",
    "        where period = 4\n",
    "    \"\"\"\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    all_times = pd.read_sql(query, ENGINE)\n",
    "    updates = []\n",
    "    for _, time in all_times.iterrows():\n",
    "        get_db_time = time['pctimestring']\n",
    "        minutes, seconds = map(int, get_db_time.split(':'))\n",
    "        q4_time = timedelta(minutes=minutes, seconds=seconds)\n",
    "        time_to_be_added = q4_time.total_seconds()\n",
    "        updates.append((time_to_be_added, time['game_id'], time['eventnum']))\n",
    "    update_query = \"\"\"\n",
    "        update play_by_play_q4\n",
    "        set time_left = %s\n",
    "        where game_id = %s and eventnum = %s\n",
    "    \"\"\"\n",
    "    execute_batch(cursor, update_query, updates, page_size=1000)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    cursor.close()\n",
    "    print(f\"Updated {len(updates)} rows successfully\")\n",
    "\n",
    "def str_time_to_timedelta(time_str):\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return timedelta(minutes=minutes, seconds=seconds)\n",
    "\n",
    "def game_date():\n",
    "    query = \"\"\"\n",
    "        select distinct game_id from play_by_play_q4\n",
    "        where game_date is null\n",
    "    \"\"\"\n",
    "    conn = ENGINE.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    all_game_ids = pd.read_sql(query,ENGINE)\n",
    "    try:\n",
    "        for _, row in all_game_ids.iterrows():\n",
    "            update_batch = []\n",
    "            game_id = row['game_id']\n",
    "            box_score = boxscoresummaryv2.BoxScoreSummaryV2(game_id)\n",
    "            time.sleep(CONFIGS['api_call_sleep'])\n",
    "            box_score_df = box_score.get_data_frames()[0]\n",
    "            date = pd.to_datetime(box_score_df[\"GAME_DATE_EST\"].iloc[0]).date()\n",
    "            game_id_query = \"\"\"\n",
    "                select eventnum from play_by_play_q4\n",
    "                where game_id = %s\n",
    "            \"\"\"\n",
    "            cursor.execute(game_id_query, (game_id,))\n",
    "            all_event_num = cursor.fetchall()\n",
    "            for event in all_event_num:\n",
    "                eventnum = event[0]\n",
    "                update_batch.append((date, game_id, eventnum))\n",
    "            update_query = \"\"\"\n",
    "                update play_by_play_q4 \n",
    "                set game_date = %s\n",
    "                where game_id = %s and eventnum = %s\n",
    "            \"\"\"\n",
    "            execute_batch(cursor, update_query, update_batch, page_size=1000)\n",
    "            conn.commit()\n",
    "            print(f\"updated {len(update_batch)} rows for {game_id}\")\n",
    "        close_db()\n",
    "        print(f\"successfully updated all rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing game {game_id}: {e}\")\n",
    "        if \"HTTPSConnectionPool\" in str(e):\n",
    "            print(\"Detected connection issue, restarting notebook...\")\n",
    "            close_db()\n",
    "            restart_run_notebook(NOTEBOOK_PATH)\n",
    "            return\n",
    "        \n",
    "def close_db():\n",
    "    # Close database connections\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"Database connections closed\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    game_date()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
