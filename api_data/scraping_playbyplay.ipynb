{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d724977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connected successfully\n",
      "Table play_by_play_q4 altered successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from nba_api.stats.endpoints import playbyplayv2, leaguegamefinder\n",
    "from sqlalchemy import create_engine, text\n",
    "import subprocess\n",
    "import sys\n",
    "import papermill as pm\n",
    "def get_db_config():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('db.ini')\n",
    "    \n",
    "    return {\n",
    "        'database': config['postgresql']['database'],\n",
    "        'user': config['postgresql']['user'],\n",
    "        'password': config['postgresql']['password'],\n",
    "        'host': config['postgresql']['host'],\n",
    "        'port': config['postgresql']['port']\n",
    "    }\n",
    "\n",
    "def create_table():\n",
    "    try:      \n",
    "        # Create the play_by_play_q4 table if it doesn't exist\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS play_by_play_q4 (\n",
    "            game_id VARCHAR(20),\n",
    "            eventnum INT,\n",
    "            eventmsgtype INT,\n",
    "            eventmsgactiontype INT,\n",
    "            period INT,\n",
    "            wctimestring VARCHAR(20),\n",
    "            pctimestring VARCHAR(20),\n",
    "            homedescription TEXT,\n",
    "            neutraldescription TEXT,\n",
    "            visitordescription TEXT,\n",
    "            score VARCHAR(20),\n",
    "            scoremargin VARCHAR(10),\n",
    "            PRIMARY KEY (game_id, eventnum)\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Table play_by_play_q4 created successfully or already exists\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def alter_table():\n",
    "    try: \n",
    "        alter_table_query = \"\"\"\n",
    "        ALTER TABLE play_by_play_q4\n",
    "        ADD COLUMN IF NOT EXISTS home_players INT[],\n",
    "        ADD COLUMN IF NOT EXISTS away_players INT[],\n",
    "        ADD COLUMN IF NOT EXISTS home_3pt_percentage INT[],\n",
    "        ADD COLUMN IF NOT EXISTS away_3pt_percentage INT[],\n",
    "        ADD COLUMN IF NOT EXISTS home_freethrow_percentage INT[],\n",
    "        ADD COLUMN IF NOT EXISTS away_freethrow_percentage INT[];\n",
    "        \"\"\"\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "        print(\"Table play_by_play_q4 altered successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "# connect to database \n",
    "db_config = get_db_config()\n",
    "conn = psycopg2.connect(\n",
    "    database=db_config['database'],\n",
    "    user=db_config['user'],\n",
    "    password=db_config['password'],\n",
    "    host=db_config['host'],\n",
    "    port=db_config['port']\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "print(\"Database connected successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c2817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching game IDs from NBA API...\n",
      "Fetching 2024-25 Regular Season games\n",
      "Found 1230 games for 2024-25 Regular Season\n",
      "Fetching 2024-25 Playoffs games\n",
      "Found 66 games for 2024-25 Playoffs\n",
      "Fetching 2023-24 Regular Season games\n",
      "Found 1230 games for 2023-24 Regular Season\n",
      "Fetching 2023-24 Playoffs games\n",
      "Found 82 games for 2023-24 Playoffs\n",
      "Fetching 2022-23 Regular Season games\n",
      "Found 1230 games for 2022-23 Regular Season\n",
      "Fetching 2022-23 Playoffs games\n",
      "Found 84 games for 2022-23 Playoffs\n",
      "Fetching 2021-22 Regular Season games\n",
      "Found 1230 games for 2021-22 Regular Season\n",
      "Fetching 2021-22 Playoffs games\n",
      "Found 87 games for 2021-22 Playoffs\n",
      "Fetching 2020-21 Regular Season games\n",
      "Found 1080 games for 2020-21 Regular Season\n",
      "Fetching 2020-21 Playoffs games\n",
      "Found 85 games for 2020-21 Playoffs\n",
      "Fetching 2019-20 Regular Season games\n",
      "Found 1059 games for 2019-20 Regular Season\n",
      "Fetching 2019-20 Playoffs games\n",
      "Found 83 games for 2019-20 Playoffs\n",
      "Fetching 2018-19 Regular Season games\n",
      "Found 1230 games for 2018-19 Regular Season\n",
      "Fetching 2018-19 Playoffs games\n",
      "Found 82 games for 2018-19 Playoffs\n",
      "Fetching 2017-18 Regular Season games\n",
      "Found 1230 games for 2017-18 Regular Season\n",
      "Fetching 2017-18 Playoffs games\n",
      "Found 82 games for 2017-18 Playoffs\n",
      "Fetching 2016-17 Regular Season games\n",
      "Found 1230 games for 2016-17 Regular Season\n",
      "Fetching 2016-17 Playoffs games\n",
      "Found 79 games for 2016-17 Playoffs\n",
      "Fetching 2015-16 Regular Season games\n",
      "Found 1230 games for 2015-16 Regular Season\n",
      "Fetching 2015-16 Playoffs games\n",
      "Found 86 games for 2015-16 Playoffs\n",
      "Fetching 2014-15 Regular Season games\n",
      "Found 1230 games for 2014-15 Regular Season\n",
      "Fetching 2014-15 Playoffs games\n",
      "Found 81 games for 2014-15 Playoffs\n",
      "Found 14106 total across 2014-2025 seasons\n",
      "Checking for existing games in database...\n",
      "Found 14105 existing games in database\n",
      "Found 14105 existing games from 2014-15 through 2024-25 seasons\n",
      "Processing 1 new games\n",
      "[1/1] Fetching for 0042400227\n",
      "Added 106 plays for game 0042400227\n",
      "Data import completed\n"
     ]
    }
   ],
   "source": [
    "# all configurations for nba api requests\n",
    "CONFIGS = {\n",
    "    'api_call_sleep' : .600,\n",
    "    'batch_size' : 1000,\n",
    "    'seasons' : [\n",
    "        '2024-25',\n",
    "        '2023-24',\n",
    "        '2022-23',\n",
    "        '2021-22',\n",
    "        '2020-21',\n",
    "        '2019-20',\n",
    "        '2018-19',\n",
    "        '2017-18',\n",
    "        '2016-17',\n",
    "        '2015-16',\n",
    "        '2014-15',\n",
    "    ],\n",
    "    'season_types' : ['Regular Season', 'Playoffs'],\n",
    "    'min_quarter': 4,\n",
    "}\n",
    "\n",
    "NOTEBOOK_PATH = \"..\\\\api_data\\\\scraping_playbyplay.ipynb\"\n",
    "\n",
    "# Create SQLAlchemy engine for pandas to_sql functionality\n",
    "CONNECTION_STR = (\n",
    "    f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}\"\n",
    "    f\"@{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    ")\n",
    "ENGINE = create_engine(CONNECTION_STR)\n",
    "\n",
    "def restart_run_notebook(nb_path=NOTEBOOK_PATH):\n",
    "    \"\"\"\n",
    "    Rerunning the notebook because of API call bottleneck:\n",
    "    HTTPSConnectionPool(host='stats.nba.com', port=443): Read timed out. (read timeout=30)\n",
    "    There are probably better solutions but resetting the kernel was the solution that worked out for me\n",
    "    \"\"\"\n",
    "    print(f\"Re-running notebook via Papermill: {nb_path}\")\n",
    "    pm.execute_notebook(\n",
    "        nb_path,       \n",
    "        nb_path,           \n",
    "        log_output=True,\n",
    "        timeout=None\n",
    "    )\n",
    "    print(\"Notebook run complete.\")\n",
    "\n",
    "def fetch_playbyplay():\n",
    "    # Get game IDs directly from NBA API\n",
    "    print(\"Fetching game IDs from NBA API...\")\n",
    "    game_ids = []\n",
    "    for season in CONFIGS['seasons']:\n",
    "        for season_type in CONFIGS['season_types']:\n",
    "            print(f\"Fetching {season} {season_type} games\")\n",
    "            try: \n",
    "                gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "                    season_nullable=season,\n",
    "                    season_type_nullable=season_type\n",
    "                )\n",
    "                time.sleep(CONFIGS['api_call_sleep'])\n",
    "                season_games_df = gamefinder.get_data_frames()[0]\n",
    "                season_game_ids = season_games_df['GAME_ID']\n",
    "                season_game_ids = season_game_ids[season_game_ids.astype(str).str.startswith(('002','004'))].unique().tolist()\n",
    "                game_ids.extend(season_game_ids)\n",
    "                print(f\"Found {len(season_game_ids)} games for {season} {season_type}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {season} {season_type}: {e}\")\n",
    "        time.sleep(CONFIGS['api_call_sleep'])\n",
    "    game_ids = list(set(game_ids))\n",
    "    print(f\"Found {len(game_ids)} total across 2014-2025 seasons\")\n",
    "\n",
    "    # Query existing game IDs from the database\n",
    "    print(\"Checking for existing games in database...\")\n",
    "    existing_games_query = \"SELECT DISTINCT game_id FROM play_by_play_q4\"\n",
    "    existing_games_df = pd.read_sql(existing_games_query, ENGINE)\n",
    "    existing_game_ids = set(existing_games_df['game_id'].astype(str).tolist() if not existing_games_df.empty else [])\n",
    "    print(f\"Found {len(existing_game_ids)} existing games in database\")\n",
    "    season_patterns = [f\"game_id LIKE '0021{i}%%'\" for i in range(4, 10)] + [f\"game_id LIKE '0022{i}%%'\" for i in range(0, 5)] + [f\"game_id LIKE '0041{i}%%'\" for i in range(4, 10)] + [f\"game_id LIKE '0042{i}%%'\" for i in range(0, 5)]\n",
    "    season_conditions = \" OR \".join(season_patterns)\n",
    "    specific_season_query = f\"SELECT DISTINCT game_id FROM play_by_play_q4 WHERE {season_conditions}\"\n",
    "    specific_df = pd.read_sql(specific_season_query, ENGINE)\n",
    "    specific_id = set(specific_df['game_id'].astype(str).tolist() if not specific_df.empty else [])\n",
    "    print(f\"Found {len(specific_id)} existing games from 2014-15 through 2024-25 seasons\")\n",
    "\n",
    "    # Filter for only new game IDs\n",
    "    new_game_ids = [game_id for game_id in game_ids if game_id not in existing_game_ids]\n",
    "    print(f\"Processing {len(new_game_ids)} new games\")\n",
    "        \n",
    "    # Fetch and insert play-by-play data for each game\n",
    "    for i, game_id in enumerate(new_game_ids):\n",
    "        try:\n",
    "            print(f\"[{i+1}/{len(new_game_ids)}] Fetching for {game_id}\")\n",
    "            pbp = playbyplayv2.PlayByPlayV2(game_id=game_id)\n",
    "            time.sleep(CONFIGS['api_call_sleep'])\n",
    "            df = pbp.get_data_frames()[0]\n",
    "            df = df[df[\"PERIOD\"] >= CONFIGS['min_quarter']]  # Filter for 4th/ot quarter only\n",
    "                \n",
    "            if not df.empty:\n",
    "                # Convert all column names to lowercase to match PostgreSQL default behavior\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "                    \n",
    "                # Check which columns from df match our table schema\n",
    "                cursor.execute(\"SELECT * FROM play_by_play_q4 LIMIT 0\")\n",
    "                colnames = [desc[0].lower() for desc in cursor.description]\n",
    "                    \n",
    "                # Only keep columns that exist in our schema\n",
    "                df_filtered = df[[col for col in df.columns if col in colnames]]\n",
    "                    \n",
    "                # Use if_exists='append' to add to existing table\n",
    "                df_filtered.to_sql(\"play_by_play_q4\", ENGINE, if_exists=\"append\", index=False, method='multi', chunksize=CONFIGS['batch_size'])\n",
    "                print(f\"Added {len(df_filtered)} plays for game {game_id}\")\n",
    "            else:\n",
    "                print(f\"No 4th quarter data found for game {game_id}\")\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(f\"Error on {game_id}: {e}\")\n",
    "            if \"HTTPSConnectionPool\" in str(e):\n",
    "                print(\"Detected connection issue, restarting notebook\")\n",
    "                close_db()\n",
    "                restart_run_notebook(NOTEBOOK_PATH)\n",
    "                return       \n",
    "            # adds the game id anyways\n",
    "            if \"duplicate key value violates unique constraint\" in str(e):\n",
    "                with ENGINE.begin() as conn:\n",
    "                    for _, row in df_filtered.iterrows():\n",
    "                        row_dict = row.to_dict()\n",
    "                        columns = row_dict.keys()\n",
    "\n",
    "                        insert_cols = \", \".join(columns)\n",
    "                        placeholders = \", \".join([f\":{col}\" for col in columns])\n",
    "                        update_cols = [f\"{col} = EXCLUDED.{col}\" for col in columns if col not in (\"game_id\", \"eventnum\")]\n",
    "                        update_clause = \", \".join(update_cols)\n",
    "\n",
    "                        query = text(f\"\"\"\n",
    "                            INSERT INTO play_by_play_q4 ({insert_cols})\n",
    "                            VALUES ({placeholders})\n",
    "                            ON CONFLICT (game_id, eventnum)\n",
    "                            DO UPDATE SET {update_clause}\n",
    "                        \"\"\")\n",
    "\n",
    "                        conn.execute(query, row_dict)\n",
    "                        print(\"game updated in database\")\n",
    "    print(\"Data import completed\")\n",
    "\n",
    "def players_on_court():\n",
    "    existing_games_query = \"SELECT DISTINCT game_id FROM play_by_play_q4\"\n",
    "    existing_games_df = pd.read_sql(existing_games_query, ENGINE)\n",
    "    \n",
    "    print(\"successfully imported players on the court during each play\")\n",
    "\n",
    "def remove_games():\n",
    "    with ENGINE.begin() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            DELETE FROM play_by_play_q4\n",
    "            WHERE NOT (\n",
    "                game_id LIKE '0021%' OR \n",
    "                game_id LIKE '0022%' OR \n",
    "                game_id LIKE '0041%' OR \n",
    "                game_id LIKE '0042%'\n",
    "            );\n",
    "        \"\"\"))\n",
    "    print(\"Deleted all games not starting with 0021, 0022, 0041, or 0042\")\n",
    "\n",
    "def close_db():\n",
    "    # Close database connections\n",
    "    if 'cursor' in locals():\n",
    "        conn.close()\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "    print(\"Database connections closed\")\n",
    "if __name__ == '__main__':\n",
    "    players_on_court()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
